1:"$Sreact.fragment"
2:I[33716,["/_next/static/chunks/a5494b77204598c0.js","/_next/static/chunks/ddbba66711dfefbf.js","/_next/static/chunks/55891c9ce3e41292.js"],"default"]
e:I[48349,["/_next/static/chunks/a5494b77204598c0.js","/_next/static/chunks/ddbba66711dfefbf.js","/_next/static/chunks/55891c9ce3e41292.js"],"default"]
f:I[97367,["/_next/static/chunks/ff1a16fafef87110.js","/_next/static/chunks/247eb132b7f7b574.js"],"OutletBoundary"]
10:"$Sreact.suspense"
:HL["/_next/static/chunks/3012c019bc39fca1.css","style"]
:HL["/_next/static/chunks/a4d58bef501c3fa7.css","style"]
0:{"buildId":"uAnJiC5wotGsCiTtg_rpM","rsc":["$","$1","c",{"children":[["$","main",null,{"className":"page-with-contents","children":[["$","$L2",null,{"articles":[{"id":"jgi-genome-portal","title":"JGI Genome Portal"},{"id":"biopig-hadoop-based-genomic-analysis-toolkit","title":"BioPig: Hadoop-based Genomic Analysis Toolkit"},{"id":"jitterbit-data-integration-platform-ipaas","title":"Jitterbit Data Integration Platform (iPaaS)"},{"id":"commerceroute-data-integration-and-workflow-solutions","title":"CommerceRoute Data Integration and Workflow Solutions"},{"id":"query-estimator-for-petabyte-storage-systems","title":"Query Estimator for Petabyte Storage Systems"},{"id":"compressed-bitmap-index-implementation","title":"Compressed Bitmap Index Implementation"},{"id":"cosmic-microwave-background-cmb-spectrum-analysis","title":"Cosmic Microwave Background (CMB) Spectrum Analysis"},{"id":"isotope-explorer","title":"Isotope Explorer"},{"id":"batmud","title":"BatMUD"}]}],["$","section",null,{"className":"card-grid","children":[["$","div",null,{"className":"card","id":"jgi-genome-portal","children":[["$","div",null,{"className":"card-title","children":"JGI Genome Portal"}],["$","div",null,{"className":"card-text","children":"The Genome Portal is a large-scale web site providing researchers globally with tools to access and interpret petabytes of genomic data generated by the Joint Genome Institute. As Team Lead, I was responsible for this portal, which provides access to data at multiple stages of genome analysis and annotation pipelines. This work also included overseeing the shift to Jenkins for build and deployment automation, replacing older Perl scripts."}]]}],["$","div",null,{"className":"card","id":"biopig-hadoop-based-genomic-analysis-toolkit","children":[["$","div",null,{"className":"card-title","children":"BioPig: Hadoop-based Genomic Analysis Toolkit"}],["$","div",null,{"className":"card-text","children":"This project involved developing BioPig, a Hadoop-based framework extending Apache Pig, specifically designed for large-scale genomic data analysis. This toolkit was introduced to address the \"data deluge\" resulting from the exponential growth of sequence data, making it one of the key solutions that scale to handle massive data and computational needs in bioinformatics."}]]}],["$","div",null,{"className":"card","id":"jitterbit-data-integration-platform-ipaas","children":[["$","div",null,{"className":"card-title","children":"Jitterbit Data Integration Platform (iPaaS)"}],["$","div",null,{"className":"card-text","children":"As a co-founder and Chief Software Architect, I developed Jitterbit into a cloud-based data integration company recognized as a leader and visionary in the iPaaS field. The solution expanded a prior product to include the ability to call and host web services, offering visual mapping for integration across structures like XML, databases, LDAP directories, and multiple cloud applications (e.g., Salesforce.com, NetSuite)."}]]}],["$","div",null,{"className":"card","id":"commerceroute-data-integration-and-workflow-solutions","children":[["$","div",null,{"className":"card-title","children":"CommerceRoute Data Integration and Workflow Solutions"}],["$","div",null,{"className":"card-text","children":"This suite of products began with the architecture and implementation of SilkRoute (later WebWorkflow), a core workflow/Business Process Modeling product featuring a client tool, a rule database, and an engine written in C++ and ported to Linux and Solaris. Building upon this powerful engine, I developed the CommerceRoute data integration solution, which handles transformations and transfers between sources and targets (including FTP, SAP, databases, and formats like XML/EDI) and implements the RosettaNet B2B framework. The complete solution was later sold as the Syncx integration appliance, reducing support costs by limiting customer access strictly to a web browser."}]]}],"$L3","$L4","$L5","$L6","$L7","$L8"]}]]}],["$L9","$La","$Lb","$Lc"],"$Ld"]}],"loading":null,"isPartial":false}
3:["$","div",null,{"className":"card","id":"query-estimator-for-petabyte-storage-systems","children":[["$","div",null,{"className":"card-title","children":"Query Estimator for Petabyte Storage Systems"}],["$","div",null,{"className":"card-text","children":"This component was developed as part of a Department of Energy (DOE) Grand Challenge project focused on handling petabytes (in 1998) of data stored on robotic tape systems (HPSS). The Query Estimator utilizes a compressed bitmap index I researched and implemented to quickly estimate the size of a result set for a particular query before the data retrieval request is executed, optimizing access to massive multi-dimensional datasets. The distributed system coordinating this storage access relied on CORBA for inter-component communication."}]]}]
4:["$","div",null,{"className":"card","id":"compressed-bitmap-index-implementation","children":[["$","div",null,{"className":"card-title","children":"Compressed Bitmap Index Implementation"}],["$","div",null,{"className":"card-text","children":"I researched and implemented a specialized compressed bitmap index that is highly effective for range queries. A key feature of this work is the ability to perform query execution directly without needing to decompress the index first, enhancing performance for high-dimensional data problems. This work was published in a scientific paper titled \"Notes on Design and Implementation of Compressed Bit Vectors\"."}]]}]
5:["$","div",null,{"className":"card","id":"cosmic-microwave-background-cmb-spectrum-analysis","children":[["$","div",null,{"className":"card-title","children":"Cosmic Microwave Background (CMB) Spectrum Analysis"}],["$","div",null,{"className":"card-text","children":"This research involved a detailed analysis of observations related to the Cosmic Microwave Background (CMB) radiation intensity, a relic of the Big Bang. The resulting analysis provided new, more precise values for the best fit temperature of the CMB (2.7356 Â± 0.0038 K at 95% CL) and calculated the speed of our solar system relative to the CMB."}]]}]
6:["$","div",null,{"className":"card","id":"isotope-explorer","children":[["$","div",null,{"className":"card-title","children":"Isotope Explorer"}],["$","div",null,{"className":"card-text","children":"In 1995 I moved to Berkeley to work on a visualization tool for nuclei of isotopes at Lawrence Berkeley Laboratory. Originally called VuENSDF, it is a tool for exploring the nuclear data from the ENSDF database. Up till then, when you needed to access nuclear energy level data, you used the Table of Isotopes (ToI), which was a thick book. ToI was published by the Isotopes Project, a research group at the Nuclear Science Division of LBL. That group was headed by Nobel Laureate Glenn T. Seaborg, who still checked in on us from time to time. Dr. Seaborg was famous for the discovery of the elements plutonium, americium, curium, berkelium, californium, einsteinium, fermium, mendelevium, nobelium, and seaborgium."}],["$","div",null,{"className":"card-subtitle pt-4","children":"Technology"}],["$","div",null,{"className":"card-text","children":"The tool was written in C++ and Borland's OWL library for Windows. One weekend I was reading the C code for the Unix Telnet server and decided to see if I could talk to it from Isotope Explorer. This led to us adding access to a large document set of references to the nuclear data. This was a web service before the term was invented."}],["$","div",null,{"className":"card-subtitle pt-4","children":"Features"}],["$","div",null,{"className":"card-text","children":["Isotope Explorer can display level drawings, coincidences, tables, band plots, nuclear charts, chart data and literature references.",["$","$Le",null,{"src":"/img/isotope-explorer.png","alt":"Isotope Explorer","width":800,"height":600,"className":"pt-4 pb-4"}]]}]]}]
7:["$","div",null,{"className":"card","id":"batmud","children":[["$","div",null,{"className":"card-title","children":"BatMUD"}],["$","div",null,{"className":"card-text","children":"A MUD (Multi-User Dungeon) is an online role-playing game. In 1991 I was at the university and joined BatMUD as a player. Back then you accessed the game via a telnet client. I wizzed (reached level 20 and beat Tiamat) and started extending the game as all wizards do. This is how I discovered my love of programming. I started working on the backend, adding a 'feelings' system and the first global event (orch raids), among other things. The coding for LPC MUDs is in LPC, an object-oriented version of C. My player character is the Archwizard Plura."}]]}]
8:["$","div",null,{"className":"card hidden","children":[["$","div",null,{"className":"card-title","children":"."}],["$","div",null,{"className":"card-text","children":"."}],["$","div",null,{"className":"card-subtitle pt-4","children":"."}],["$","div",null,{"className":"card-text","children":"."}]]}]
9:["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/3012c019bc39fca1.css","precedence":"next"}]
a:["$","link","1",{"rel":"stylesheet","href":"/_next/static/chunks/a4d58bef501c3fa7.css","precedence":"next"}]
b:["$","script","script-0",{"src":"/_next/static/chunks/ddbba66711dfefbf.js","async":true}]
c:["$","script","script-1",{"src":"/_next/static/chunks/55891c9ce3e41292.js","async":true}]
d:["$","$Lf",null,{"children":["$","$10",null,{"name":"Next.MetadataOutlet","children":"$@11"}]}]
11:null
