import Contents from '../components/Contents'
import LightboxImage from '../components/LightboxImage';

const ProjectsPage = () => {
  const articles = [
    { id: 'jgi-genome-portal', title: 'JGI Genome Portal' },
    { id: 'elviz-metagenome-visualization', title: 'Elviz -- metagenome visualization' },
    {
      id: 'biopig-hadoop-based-genomic-analysis-toolkit',
      title: 'BioPig: Hadoop-based Genomic Analysis Toolkit'
    },
    {
      id: 'jitterbit-data-integration-platform-ipaas',
      title: 'Jitterbit Data Integration Platform (iPaaS)'
    },
    {
      id: 'commerceroute-data-integration-and-workflow-solutions',
      title: 'CommerceRoute Data Integration and Workflow'
    },
    {
      id: 'query-estimator-for-petabyte-storage-systems',
      title: 'Query Estimator for Petabyte Storage Systems'
    },
    {
      id: 'compressed-bitmap-index',
      title: 'Compressed Bitmap Index'
    },
    {
      id: 'cosmic-microwave-background-cmb-spectrum-analysis',
      title: 'Cosmic Microwave Background (CMB) Spectrum Analysis'
    },
    { id: 'isotope-explorer', title: 'Isotope Explorer' },
    { id: 'batmud', title: 'BatMUD' }
  ]

  return (
    <main className="page-with-contents">
      <Contents articles={articles} />
      <section className="card-grid">

        <div className="card" id="jgi-genome-portal">
          <div className="card-title">JGI Genome Portal</div>
          <div className="card-text">The Genome Portal is a large-scale web site providing researchers globally with tools to
            access and interpret petabytes of genomic data generated by the Joint Genome Institute. As Team Lead, I was
            responsible for this portal, which provides access to data at multiple stages of genome analysis and annotation
            pipelines. This work also included overseeing the shift to Jenkins for build and deployment automation, replacing
            older Perl scripts.</div>
        </div>

        <div className="card" id="elviz-metagenome-visualization">
          <div className="card-title">Elviz -- metagenome visualization</div>
          <div className="card-text">
              <LightboxImage 
                src="/img/elviz.png" 
                alt="Elviz -- metagenome visualization" 
                width={800} 
                height={600}
                className="pb-4"
              />
              Elviz (Environmental Laboratory Visualization) is an interactive web-based tool
              for the visual exploration of assembled metagenomes and their complex metadata.
              Elviz allows scientists to navigate metagenome assemblies across multiple dimensions and scales, plotting parameters
              such as GC content, relative abundance, phylogenetic affiliation and assembled contig length. Furthermore Elviz enables
              interactive exploration using real-time plot navigation, search, filters, axis selection, and the ability to drill from
              a whole-community profile down to individual gene annotations.
            </div>
            <div className="card-subtitle pt-4">Technology</div>
            <div className="card-text">
              Elviz is a web application, written in AngularJS, JavaScript, and WebGL. Try it out 
              at <a href="https://genome.jgi.doe.gov/viz">genome.jgi.doe.gov/viz</a>. We published a paper on
              it in BMC Bioinformatics in 2015: <a href="https://doi.org/10.1186/s12859-015-0566-4">Elviz – exploration
              of metagenome assemblies with an interactive visualization tool</a>.
            </div>
        </div>


        <div className="card" id="biopig-hadoop-based-genomic-analysis-toolkit">
          <div className="card-title">BioPig: Hadoop-based Genomic Analysis Toolkit</div>
          <div className="card-text">BioPig is a Hadoop-based analytic toolkit designed to scale large-scale sequence analysis
            to data volumes that overwhelm traditional tools. It sits on top of Hadoop MapReduce and the Pig data-flow language
            to provide a higher-level, more programmable framework for bioinformatics tasks, with emphasis on scalability,
            portability, and ease of use. We published a paper on it in Bioinformatics in 
            2013: <a href="https://doi.org/10.1093/bioinformatics/btt528">BioPig: a Hadoop-based analytic toolkit for large-scale sequence data</a>.
          </div>
          <div className="card-subtitle pt-4">Origin</div>
          <div className="card-text">
            In 2010, as I was working on the Genome Portal, I collaborated with Dr. Zhong Wang's Genome Analysis 
            research group at the Joint Genome Institute (JGI) to develop BioPig. Researchers at the JGI assemble genomes
            from raw sequence data using supercomputers at NERSC. BioPig was envisioned as a way to scale beyond the current
            methods. 
            It was written by me and Karan Bhatia, using Java and Pig Latin. The source code 
            is <a href="https://github.com/JGI-Bioinformatics/biopig">available on GitHub</a>.
          </div>
          <div className="card-subtitle pt-4">Performance and Scalability</div>
          <div className="card-text">
            Empirical results compare BioPig against serial and MPI implementations, using datasets from 100 Mb (Mega basepairs)
            up to 500 Gb. BioPig demonstrates near-linear scaling with data size on Hadoop clusters (e.g., Magellan/NERSC and AWS EC2),
            whereas traditional serial/MPI approaches hit memory limits or scale poorly in practice due to high-latency or 
            bespoke parallelization requirements. While there is a certain amount of overhead thanks to Hadoop’s startup,
            for very large datasets the data-analysis time dominates startup costs.
            <LightboxImage 
              src="/img/biopig-graphs.png" 
              alt="BioPig performance and scalability" 
              width={800} 
              height={600}
              className="pt-4 pb-4"
            />
          </div>
          <div className="card-subtitle pt-4">Example</div>
          <div className="card-text">Below is a simple example of a Pig script to count kmers. For more advanced
            examples, see the <a href="https://github.com/JGI-Bioinformatics/biopig/tree/master/examples">examples</a>
            directory on GitHub, or the paper.
            <pre>
              -- a simple example of pig script to count kmers<br/>
              1 register /.../biopig-core-0.3.0-job-pig.jar<br/>
              2 A = load '$input' using gov.jgi.meta.pig.storage.FastaStorage as (id: chararray, d: int, seq: bytearray, header: chararray);<br/>
              3 B = foreach A generate flatten(gov.jgi.meta.pig.eval.KmerGenerator(seq, 20)) as (kmer:bytearray);<br/>
              4 C = group B by kmer parallel $p;<br/>
              5 D = foreach C generate group, count(B);<br/>
              6 E = group D by $1 parallel $p;<br/>
              7 F = foreach E generate group, count(D);<br/>
              8 store F into '$output';<br/>
            </pre>
          </div>
        </div>

        <div className="card" id="jitterbit-data-integration-platform-ipaas">
          <div className="card-title">Jitterbit Data Integration Platform (iPaaS)</div>
          <div className="card-text">As a co-founder and Chief Software Architect, I developed Jitterbit into a cloud-based
            data integration company recognized as a leader and visionary in the iPaaS field. The solution expanded a prior
            product to include the ability to call and host web services, offering visual mapping for integration across
            structures like XML, databases, LDAP directories, and multiple cloud applications (e.g., Salesforce.com,
            NetSuite).</div>
        </div>

        <div className="card" id="commerceroute-data-integration-and-workflow-solutions">
          <div className="card-title">CommerceRoute Data Integration and Workflow Solutions</div>
          <div className="card-text">This suite of products began with the architecture and implementation of SilkRoute (later
            WebWorkflow), a core workflow/Business Process Modeling product featuring a client tool, a rule database, and an
            engine written in C++ and ported to Linux and Solaris. Building upon this powerful engine, I developed the
            CommerceRoute data integration solution, which handles transformations and transfers between sources and targets
            (including FTP, SAP, databases, and formats like XML/EDI) and implements the RosettaNet B2B framework. The
            complete solution was later sold as the Syncx integration appliance, reducing support costs by limiting customer
            access strictly to a web browser.</div>
        </div>

        <div className="card" id="query-estimator-for-petabyte-storage-systems">
          <div className="card-title">Query Estimator for Petabyte Storage Systems</div>
          <div className="card-text">This component was developed as part of a Department of Energy (DOE) Grand Challenge
            project focused on handling petabytes (in 1998) of data stored on robotic tape systems (HPSS). The Query Estimator utilizes
            a compressed bitmap index I researched and implemented to quickly estimate the size of a result set for a particular
            query before the data retrieval request is executed, optimizing access to massive multi-dimensional datasets. The
            distributed system coordinating this storage access relied on CORBA for inter-component communication.</div>
        </div>

        <div className="card" id="compressed-bitmap-index">
          <div className="card-title">Compressed Bitmap Index</div>
          <div className="card-text">I researched and implemented a specialized compressed bitmap index that is highly
            effective for range queries. A key feature of this work is the ability to perform query execution directly without
            needing to decompress the index first, enhancing performance for high-dimensional data problems. This work was
            published in a scientific paper titled "Notes on Design and Implementation of Compressed Bit Vectors".</div>
        </div>

        <div className="card" id="cosmic-microwave-background-cmb-spectrum-analysis">
          <div className="card-title">Cosmic Microwave Background (CMB) Spectrum Analysis</div>
          <div className="card-text">This research involved a detailed analysis of observations related to the Cosmic
            Microwave Background (CMB) radiation intensity, a relic of the Big Bang. The resulting analysis provided new,
            more precise values for the best fit temperature of the CMB (2.7356 ± 0.0038 K at 95% CL) and calculated the speed
            of our solar system relative to the CMB.</div>
        </div>

        <div className="card" id="isotope-explorer">
          <div className="card-title">Isotope Explorer</div>
          <div className="card-text">In 1995 I moved to Berkeley to work on a visualization tool for nuclei of isotopes 
            at Lawrence Berkeley Laboratory.
            Originally called VuENSDF, it is a tool for exploring the nuclear data from the ENSDF database. Up till then,
            when you needed to access nuclear energy level data, you used the Table of Isotopes (ToI), which was a thick book.
            ToI was published by the Isotopes Project, a research group at the Nuclear Science Division of LBL. That group was
            headed by Nobel Laureate Glenn T. Seaborg, who still checked in on us from time to time. Dr. Seaborg was famous
            for the discovery of the elements plutonium, americium, curium, berkelium, californium, einsteinium,
            fermium, mendelevium, nobelium, and seaborgium.
          </div>
          <div className="card-subtitle pt-4">Technology</div>
          <div className="card-text">
            The tool was written in C++ and Borland's OWL library for Windows. One weekend I was reading the C code for
            the Unix Telnet server and decided to see if I could talk to it from Isotope Explorer. This led to us adding
            access to a large document set of references to the nuclear data. This was a web service before the term was invented.
          </div>
          <div className="card-subtitle pt-4">Features</div>
          <div className="card-text">
            Isotope Explorer can display level drawings, coincidences, tables, band plots, nuclear charts, chart data and literature references.
            <LightboxImage 
              src="/img/isotope-explorer.png" 
              alt="Isotope Explorer" 
              width={800} 
              height={600}
              className="pt-4 pb-4"
            />
          </div>
        </div>

        <div className="card" id="batmud">
          <div className="card-title">BatMUD</div>
          <div className="card-text">A MUD (Multi-User Dungeon) is an online role-playing game. In 1991 I was at the
            university and joined BatMUD as a player. Back then you accessed the game via a telnet client.
            I wizzed (reached level 20 and beat Tiamat) and started extending the
            game as all wizards do. This is how I discovered my love of programming. I started working on the backend, adding a
            'feelings' system and the first global event (orch raids), among other things. The coding for LPC MUDs is in LPC, an object-oriented
            version of C. My player character is the Archwizard Plura.</div>
        </div>

        <div className="card hidden">
          <div className="card-title">.</div>
          <div className="card-text">.
          </div>
          <div className="card-subtitle pt-4">.</div>
          <div className="card-text">.
          </div>
        </div>
      </section>
    </main>
  )
}

export default ProjectsPage;
