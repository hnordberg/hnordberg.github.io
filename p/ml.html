<!DOCTYPE html><!--n7JqkWY1I6Zu1oUapzzgq--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/chunks/709d76917318ea58.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/chunks/0c61c8691d9d95a7.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/2e777329c8f64894.js"/><script src="/_next/static/chunks/01787aef0bc207ac.js" async=""></script><script src="/_next/static/chunks/8296bf97416a5ebf.js" async=""></script><script src="/_next/static/chunks/94bde6376cf279be.js" async=""></script><script src="/_next/static/chunks/turbopack-a95fe599ef02cde8.js" async=""></script><script src="/_next/static/chunks/dc293e429f126484.js" async=""></script><script src="/_next/static/chunks/ff1a16fafef87110.js" async=""></script><script src="/_next/static/chunks/247eb132b7f7b574.js" async=""></script><script src="/_next/static/chunks/35d043138a0d6b40.js" async=""></script><title>Henrik Nordberg, Principal Engineer</title><meta name="description" content="Henrik Nordberg&#x27;s project showcase"/><link rel="shortcut icon" href="/favicon.ico"/><link rel="icon" href="/favicon.ico"/><link rel="apple-touch-icon" href="/favicon.ico"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><header><nav id="main-nav" class=""><div class="nav-mobile-header"><button class="hamburger-menu" aria-label="Toggle menu" aria-expanded="false"><span></span> <span></span><span></span></button><span class="mobile-name">Henrik Nordberg</span></div><ul class=""><li><a class="" href="/">Home</a></li><li><a class="" href="/projects">Projects</a></li><li><a class="" href="/technology">Technology</a></li><li><a class="" href="/leadership">Leadership</a></li><li><a class="" href="/publications">Publications</a></li><li><a class="" href="/contact">Contact</a></li></ul></nav><div class="ThemeSwitcher-module__I_Ny3W__themeSwitchContainer"><input type="checkbox" id="checkbox" class="ThemeSwitcher-module__I_Ny3W__checkbox" title="Toggle theme" aria-label="Toggle theme"/><label for="checkbox" class="ThemeSwitcher-module__I_Ny3W__label"></label></div></header><main><div class="text-center pt-8 pb-4"><h1 class="text-4xl font-bold">History of Machine Learning &amp; LLMs</h1><p class="text-lg text-gray-600 dark:text-gray-400">Disclaimer: I used various LLMs to generate the data for this timeline.</p></div><section aria-label="Timeline" class="container mx-auto px-4 py-8"><div class="relative"><div aria-hidden="true" class="Timeline-module__msIhgq__line z-10"></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">1957</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">1957</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Perceptron at Cornell Aeronautical Laboratory" alt="Perceptron at Cornell Aeronautical Laboratory" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/cornell.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Perceptron">Details</button><h3 class="font-semibold text-lg">Perceptron</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Cornell Aeronautical Laboratory</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Frank Rosenblatt</span></div><p class="text-xs mt-1">Paper: <a href="https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">The Perceptron: A Perceiving and Recognizing Automaton</a></p><p class="mt-2 whitespace-pre-line">The Perceptron was the first model that could learn the weights defining categories given examples from each category. It established the foundation for artificial neural networks by introducing a learning algorithm that could automatically adjust connection weights. The perceptron demonstrated that machines could learn from experience, marking a fundamental breakthrough in machine learning.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">1980</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">1980</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Neocognitron at NHK Science &amp; Technical Research Laboratories" alt="Neocognitron at NHK Science &amp; Technical Research Laboratories" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/nhk.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Neocognitron">Details</button><h3 class="font-semibold text-lg">Neocognitron</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">NHK Science &amp; Technical Research Laboratories</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Kunihiko Fukushima</span></div><p class="text-xs mt-1">Paper: <a href="https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position</a></p><p class="mt-2 whitespace-pre-line">The Neocognitron was a hierarchical, multilayered neural network inspired by the visual cortex. It introduced the concepts of S-cells (simple cells) and C-cells (complex cells) arranged in a hierarchy, allowing for position-invariant pattern recognition. This architecture laid the groundwork for modern convolutional neural networks and demonstrated that local feature extraction combined with spatial pooling could achieve robust visual recognition.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">1986</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">1986</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Backpropagation at University of California San Diego, Carnegie Mellon University, University of Toronto" alt="Backpropagation at University of California San Diego, Carnegie Mellon University, University of Toronto" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/ucsd.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Backpropagation">Details</button><h3 class="font-semibold text-lg">Backpropagation</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">University of California San Diego, Carnegie Mellon University, University of Toronto</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>David E. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams</span></div><p class="text-xs mt-1">Paper: <a href="https://www.nature.com/articles/323533a0" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Learning Representations by Back-propagating Errors</a></p><p class="mt-2 whitespace-pre-line">Backpropagation provided an efficient method for training multi-layer neural networks by computing gradients through the chain rule. This algorithm enabled the training of deep networks by propagating error signals backwards through layers, allowing hidden units to learn internal representations. Backpropagation became the workhorse of neural network training and remains fundamental to modern deep learning.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">1997</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">1997</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Long Short-Term Memory (LSTM) at Technische Universität München" alt="Long Short-Term Memory (LSTM) at Technische Universität München" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/tum.gif"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Long Short-Term Memory (LSTM)">Details</button><h3 class="font-semibold text-lg">Long Short-Term Memory (LSTM)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Technische Universität München</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Sepp Hochreiter, Jürgen Schmidhuber</span></div><p class="text-xs mt-1">Paper: <a href="https://deeplearning.cs.cmu.edu/S23/document/readings/LSTM.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Long Short-Term Memory</a></p><p class="mt-2 whitespace-pre-line">LSTM addressed the vanishing gradient problem in recurrent neural networks by introducing memory cells with gating mechanisms. The architecture uses input, output, and forget gates to control information flow, enabling networks to learn long-term dependencies. LSTM became the dominant architecture for sequence modeling tasks including speech recognition, machine translation, and time series prediction before the transformer era.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">1998</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">1998</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Convolutional Neural Networks (LeNet) at AT&amp;T Bell Laboratories" alt="Convolutional Neural Networks (LeNet) at AT&amp;T Bell Laboratories" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/bell_labs.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Convolutional Neural Networks (LeNet)">Details</button><h3 class="font-semibold text-lg">Convolutional Neural Networks (LeNet)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">AT&amp;T Bell Laboratories</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner</span></div><p class="text-xs mt-1">Paper: <a href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Gradient-Based Learning Applied to Document Recognition</a></p><p class="mt-2 whitespace-pre-line">LeNet introduced a practical convolutional neural network architecture for document recognition. It combined convolutional layers for local feature extraction, pooling for spatial invariance, and fully connected layers for classification. This architecture demonstrated that CNNs could be trained end-to-end using backpropagation and achieved state-of-the-art results on handwritten digit recognition, establishing the blueprint for modern computer vision systems.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2003</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2003</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="The Neural Probabilistic Language Model at Université de Montréal" alt="The Neural Probabilistic Language Model at Université de Montréal" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/montreal.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for The Neural Probabilistic Language Model">Details</button><h3 class="font-semibold text-lg">The Neural Probabilistic Language Model</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Université de Montréal</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Yoshua Bengio, Réjean Ducharme, Pascal Vincent, Christian Jauvin</span></div><p class="text-xs mt-1">Paper: <a href="https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">A Neural Probabilistic Language Model</a></p><p class="mt-2 whitespace-pre-line">The Neural Probabilistic Language Model addressed the curse of dimensionality in language modeling by learning distributed representations for words. It introduced the idea that similar words would have similar vector representations, allowing the model to generalize to unseen word sequences. This foundational work pioneered the use of neural networks for language modeling and word embeddings, directly inspiring Word2Vec and modern language models.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2009</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2009</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="ImageNet Dataset at Princeton University" alt="ImageNet Dataset at Princeton University" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/princeton.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for ImageNet Dataset">Details</button><h3 class="font-semibold text-lg">ImageNet Dataset</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Princeton University</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei</span></div><p class="text-xs mt-1">Paper: <a href="https://www.image-net.org/static_files/papers/imagenet_cvpr09.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">ImageNet: A Large-Scale Hierarchical Image Database</a></p><p class="mt-2 whitespace-pre-line">ImageNet created a large-scale dataset with over 14 million labeled images across thousands of categories, organized hierarchically using WordNet. The annual ImageNet Large Scale Visual Recognition Challenge (ILSVRC) became the premier benchmark for computer vision. ImageNet&#x27;s scale and diversity enabled the training of deep neural networks and catalyzed the deep learning revolution, particularly with AlexNet&#x27;s breakthrough in 2012.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2010</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2010</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Xavier/Glorot Initialization at Université de Montréal" alt="Xavier/Glorot Initialization at Université de Montréal" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/montreal.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Xavier/Glorot Initialization">Details</button><h3 class="font-semibold text-lg">Xavier/Glorot Initialization</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Université de Montréal</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Xavier Glorot, Yoshua Bengio</span></div><p class="text-xs mt-1">Paper: <a href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Understanding the Difficulty of Training Deep Feedforward Neural Networks</a></p><p class="mt-2 whitespace-pre-line">Xavier initialization provided a principled method for initializing neural network weights to maintain consistent variance of activations and gradients across layers. By scaling initial weights based on the number of input and output connections, it prevented vanishing or exploding gradients during training. This simple but crucial technique enabled the training of much deeper networks and remains a standard practice in deep learning.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2010</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2010</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Rectified Linear Unit (ReLU) Activation at University of Toronto" alt="Rectified Linear Unit (ReLU) Activation at University of Toronto" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/toronto.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Rectified Linear Unit (ReLU) Activation">Details</button><h3 class="font-semibold text-lg">Rectified Linear Unit (ReLU) Activation</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">University of Toronto</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Vinod Nair, Geoffrey E. Hinton</span></div><p class="text-xs mt-1">Paper: <a href="https://www.cs.toronto.edu/~fritz/absps/reluICML.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Rectified Linear Units Improve Restricted Boltzmann Machines</a></p><p class="mt-2 whitespace-pre-line">ReLU introduced a simple non-saturating activation function f(x) = max(0, x) that addressed the vanishing gradient problem of sigmoid and tanh activations. ReLU enabled faster training, reduced computational cost, and induced sparsity in neural networks. Despite its simplicity, ReLU became the default activation function for deep neural networks and enabled the training of much deeper architectures.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2012</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2012</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="AlexNet at University of Toronto" alt="AlexNet at University of Toronto" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/toronto.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for AlexNet">Details</button><h3 class="font-semibold text-lg">AlexNet</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">University of Toronto</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton</span></div><p class="text-xs mt-1">Paper: <a href="https://proceedings.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">ImageNet Classification with Deep Convolutional Neural Networks</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/akrizhevsky/cuda-convnet2" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">cuda-convnet2</a></p><p class="mt-2 whitespace-pre-line">AlexNet won the ImageNet 2012 competition with a significant margin, demonstrating that deep convolutional networks trained with GPUs could dramatically outperform traditional computer vision methods. The architecture combined ReLU activations, dropout regularization, data augmentation, and GPU training. AlexNet&#x27;s success marked the beginning of the deep learning era and sparked intense interest in neural networks across academia and industry.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2012</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2012</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Dropout at University of Toronto" alt="Dropout at University of Toronto" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/toronto.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Dropout">Details</button><h3 class="font-semibold text-lg">Dropout</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">University of Toronto</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov</span></div><p class="text-xs mt-1">Paper: <a href="https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a></p><p class="mt-2 whitespace-pre-line">Dropout introduced a powerful regularization technique by randomly dropping units during training, preventing co-adaptation of features. This simple method significantly reduced overfitting in deep neural networks by training an ensemble of exponentially many sub-networks. Dropout became a standard regularization technique and enabled the training of larger networks without excessive overfitting.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2013</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2013</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Word2Vec at Google" alt="Word2Vec at Google" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/google.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Word2Vec">Details</button><h3 class="font-semibold text-lg">Word2Vec</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Google</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Efficient Estimation of Word Representations in Vector Space</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/google/word2vec" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">word2vec</a></p><p class="mt-2 whitespace-pre-line">Word2Vec introduced efficient methods (Skip-gram and CBOW) for learning dense vector representations of words from large corpora. These embeddings captured semantic and syntactic relationships, enabling vector arithmetic like &#x27;king&#x27; - &#x27;man&#x27; + &#x27;woman&#x27; ≈ &#x27;queen&#x27;. Word2Vec revolutionized natural language processing by providing a scalable way to represent words as continuous vectors, becoming foundational for modern NLP.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2013</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2013</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Variational Autoencoder (VAE) at University of Amsterdam" alt="Variational Autoencoder (VAE) at University of Amsterdam" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/amsterdam.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Variational Autoencoder (VAE)">Details</button><h3 class="font-semibold text-lg">Variational Autoencoder (VAE)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">University of Amsterdam</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Diederik P. Kingma, Max Welling</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1312.6114.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Auto-Encoding Variational Bayes</a></p><p class="mt-2 whitespace-pre-line">VAE introduced a probabilistic approach to learning latent representations by combining variational inference with neural networks. It learns a distribution over latent codes rather than deterministic encodings, enabling both efficient inference and generation. VAE provided a principled framework for generative modeling and became influential in unsupervised learning, representation learning, and generative AI.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2014</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2014</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Generative Adversarial Network (GAN) at Université de Montréal" alt="Generative Adversarial Network (GAN) at Université de Montréal" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/montreal.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Generative Adversarial Network (GAN)">Details</button><h3 class="font-semibold text-lg">Generative Adversarial Network (GAN)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Université de Montréal</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1406.2661.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Generative Adversarial Networks</a></p><p class="mt-2 whitespace-pre-line">GAN introduced a game-theoretic framework where a generator network learns to create realistic data by competing against a discriminator network. This adversarial training process enabled the generation of highly realistic images without requiring explicit modeling of probability distributions. GANs revolutionized generative modeling and spawned numerous applications in image synthesis, style transfer, and data augmentation.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2014</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2014</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Adam Optimizer at OpenAI, University of Toronto" alt="Adam Optimizer at OpenAI, University of Toronto" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/openai.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Adam Optimizer">Details</button><h3 class="font-semibold text-lg">Adam Optimizer</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">OpenAI, University of Toronto</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Diederik P. Kingma, Jimmy Ba</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1412.6980.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Adam: A Method for Stochastic Optimization</a></p><p class="mt-2 whitespace-pre-line">Adam combined the benefits of AdaGrad and RMSProp by computing adaptive learning rates for each parameter using estimates of first and second moments of gradients. It included bias correction terms and proved robust across a wide range of problems with minimal hyperparameter tuning. Adam became the most widely used optimizer in deep learning due to its efficiency, ease of use, and strong empirical performance.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2014</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2014</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Sequence-to-Sequence Learning at Google" alt="Sequence-to-Sequence Learning at Google" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/google.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Sequence-to-Sequence Learning">Details</button><h3 class="font-semibold text-lg">Sequence-to-Sequence Learning</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Google</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Ilya Sutskever, Oriol Vinyals, Quoc V. Le</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1409.3215.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Sequence to Sequence Learning with Neural Networks</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/google/seq2seq" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">seq2seq</a></p><p class="mt-2 whitespace-pre-line">Seq2Seq introduced an end-to-end framework for sequence transduction using an encoder-decoder architecture with LSTMs. The encoder maps variable-length input sequences to fixed-size representations, which the decoder transforms into variable-length output sequences. This architecture unified many NLP tasks under a single framework and achieved breakthrough results in machine translation, establishing neural approaches as state-of-the-art.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2014</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2014</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Attention Mechanism at Université de Montréal" alt="Attention Mechanism at Université de Montréal" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/montreal.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Attention Mechanism">Details</button><h3 class="font-semibold text-lg">Attention Mechanism</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Université de Montréal</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Neural Machine Translation by Jointly Learning to Align and Translate</a></p><p class="mt-2 whitespace-pre-line">Bahdanau attention addressed the bottleneck in sequence-to-sequence models by allowing the decoder to focus on different parts of the input sequence at each decoding step. This attention mechanism computed context vectors as weighted sums of encoder hidden states, where weights were learned based on relevance. Attention became a fundamental building block of modern NLP systems and directly inspired the transformer architecture.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2014</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2014</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="GloVe Word Embeddings at Stanford University" alt="GloVe Word Embeddings at Stanford University" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/stanford.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for GloVe Word Embeddings">Details</button><h3 class="font-semibold text-lg">GloVe Word Embeddings</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Stanford University</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Jeffrey Pennington, Richard Socher, Christopher D. Manning</span></div><p class="text-xs mt-1">Paper: <a href="https://nlp.stanford.edu/pubs/glove.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">GloVe: Global Vectors for Word Representation</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/stanfordnlp/GloVe" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">GloVe</a></p><p class="mt-2 whitespace-pre-line">GloVe combined global matrix factorization with local context window methods for learning word embeddings. It trained on aggregated word-word co-occurrence statistics to produce vectors with meaningful linear substructures. GloVe provided an alternative to Word2Vec with strong performance on word analogy and similarity tasks, and its pre-trained vectors became widely used in NLP applications.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2014</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2014</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Neural Turing Machine at Google DeepMind" alt="Neural Turing Machine at Google DeepMind" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/deepmind.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Neural Turing Machine">Details</button><h3 class="font-semibold text-lg">Neural Turing Machine</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Google DeepMind</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Alex Graves, Greg Wayne, Ivo Danihelka</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1410.5401.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Neural Turing Machines</a></p><p class="mt-2 whitespace-pre-line">Neural Turing Machines extended neural networks by coupling them to external memory resources accessed through attention mechanisms. The entire system was differentiable end-to-end, allowing gradient-based training. NTMs demonstrated that neural networks could learn simple algorithms like copying, sorting, and associative recall from examples alone, showing that neural networks could exhibit more algorithmic and programmable behavior.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2015</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2015</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Batch Normalization at Google" alt="Batch Normalization at Google" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/google.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Batch Normalization">Details</button><h3 class="font-semibold text-lg">Batch Normalization</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Google</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Sergey Ioffe, Christian Szegedy</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></p><p class="mt-2 whitespace-pre-line">Batch Normalization normalized layer inputs across mini-batches, stabilizing training by reducing internal covariate shift. It enabled much higher learning rates, reduced sensitivity to initialization, and acted as a regularizer. Batch normalization dramatically accelerated training and became a standard component in deep networks, enabling the training of very deep architectures that were previously difficult to optimize.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2015</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2015</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Residual Networks (ResNet) at Microsoft Research" alt="Residual Networks (ResNet) at Microsoft Research" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/microsoft.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Residual Networks (ResNet)">Details</button><h3 class="font-semibold text-lg">Residual Networks (ResNet)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Microsoft Research</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Deep Residual Learning for Image Recognition</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/KaimingHe/deep-residual-networks" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">deep-residual-networks</a></p><p class="mt-2 whitespace-pre-line">ResNet introduced skip connections that allowed gradients to flow directly through networks by learning residual mappings. This simple architectural change enabled the training of networks with hundreds or even thousands of layers without degradation problems. ResNet won ImageNet 2015 and demonstrated that very deep networks could be effectively trained, fundamentally changing how we design neural network architectures.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2016</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2016</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Layer Normalization at University of Toronto" alt="Layer Normalization at University of Toronto" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/toronto.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Layer Normalization">Details</button><h3 class="font-semibold text-lg">Layer Normalization</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">University of Toronto</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1607.06450.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Layer Normalization</a></p><p class="mt-2 whitespace-pre-line">Layer Normalization normalized inputs across features for each example independently, unlike batch normalization which normalized across the batch dimension. This made it particularly effective for recurrent neural networks and sequences of varying length. Layer normalization stabilized hidden state dynamics in RNNs and later became the standard normalization technique in transformer architectures.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2016</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2016</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Subword Units (BPE): Solving the Rare Word Problem at University of Edinburgh" alt="Subword Units (BPE): Solving the Rare Word Problem at University of Edinburgh" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/edinburgh.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Subword Units (BPE): Solving the Rare Word Problem">Details</button><h3 class="font-semibold text-lg">Subword Units (BPE): Solving the Rare Word Problem</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">University of Edinburgh</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Rico Sennrich, Barry Haddow, Alexandra Birch</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1508.07909.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Neural Machine Translation of Rare Words with Subword Units</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/rsennrich/subword-nmt" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">subword-nmt</a></p><p class="mt-2 whitespace-pre-line">Byte-Pair Encoding (BPE) adapted a data compression algorithm for neural machine translation, enabling open-vocabulary learning by breaking words into subword units. This solved the rare word problem by representing infrequent words as sequences of common subwords. BPE became the standard tokenization approach for language models, enabling models to handle any word while maintaining reasonable vocabulary sizes, and is used in GPT, BERT, and most modern LLMs.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2017</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2017</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Transformer Architecture at Google" alt="Transformer Architecture at Google" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/google.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Transformer Architecture">Details</button><h3 class="font-semibold text-lg">Transformer Architecture</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Google</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Attention Is All You Need</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/tensorflow/tensor2tensor" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">tensor2tensor</a></p><p class="mt-2 whitespace-pre-line">The Transformer replaced recurrence and convolutions entirely with self-attention mechanisms, processing sequences in parallel rather than sequentially. It introduced multi-head attention, positional encodings, and a feedforward encoder-decoder structure. The Transformer achieved state-of-the-art translation results while being more parallelizable and requiring significantly less training time. This architecture became the foundation for modern large language models and revolutionized NLP.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2017</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2017</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Reinforcement Learning from Human Feedback (RLHF) at OpenAI, UC Berkeley, DeepMind" alt="Reinforcement Learning from Human Feedback (RLHF) at OpenAI, UC Berkeley, DeepMind" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/openai.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Reinforcement Learning from Human Feedback (RLHF)">Details</button><h3 class="font-semibold text-lg">Reinforcement Learning from Human Feedback (RLHF)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">OpenAI, UC Berkeley, DeepMind</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Paul Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, Dario Amodei</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1706.03741.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Deep Reinforcement Learning from Human Preferences</a></p><p class="mt-2 whitespace-pre-line">RLHF introduced a method for training RL agents using human preference comparisons rather than hand-crafted reward functions. Humans compared pairs of trajectory segments, and a reward model was trained to predict preferences. This reward model then guided policy optimization. RLHF scaled preference-based learning to complex tasks and later became crucial for aligning large language models with human values and intentions.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2017</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2017</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Sparsely-Gated Mixture of Experts at Google" alt="Sparsely-Gated Mixture of Experts at Google" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/google.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Sparsely-Gated Mixture of Experts">Details</button><h3 class="font-semibold text-lg">Sparsely-Gated Mixture of Experts</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Google</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, Jeff Dean</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1701.06538.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</a></p><p class="mt-2 whitespace-pre-line">Mixture of Experts introduced conditional computation where a gating network routes each input to a sparse subset of expert sub-networks. This enabled training models with orders of magnitude more parameters without proportional increases in computation. MoE demonstrated that model capacity could be dramatically increased through sparsity, achieving state-of-the-art results in language modeling and translation. This approach later influenced large-scale models like GPT-4.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2017</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2017</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Proximal Policy Optimization (PPO) at OpenAI" alt="Proximal Policy Optimization (PPO) at OpenAI" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/openai.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Proximal Policy Optimization (PPO)">Details</button><h3 class="font-semibold text-lg">Proximal Policy Optimization (PPO)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">OpenAI</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1707.06347.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Proximal Policy Optimization Algorithms</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/openai/baselines" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">baselines</a></p><p class="mt-2 whitespace-pre-line">PPO introduced a simpler and more stable policy gradient method by clipping the objective function to prevent excessively large policy updates. It combined the benefits of trust region methods with the simplicity of first-order optimization. PPO became the most widely used reinforcement learning algorithm due to its robustness, ease of implementation, and strong empirical performance across diverse tasks.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2018</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2018</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="ELMo (Embeddings from Language Models) at Allen Institute for AI, University of Washington" alt="ELMo (Embeddings from Language Models) at Allen Institute for AI, University of Washington" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/allen_ai.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for ELMo (Embeddings from Language Models)">Details</button><h3 class="font-semibold text-lg">ELMo (Embeddings from Language Models)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Allen Institute for AI, University of Washington</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Deep Contextualized Word Representations</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/allenai/bilm-tf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">bilm-tf</a></p><p class="mt-2 whitespace-pre-line">ELMo generated context-dependent word representations by using bidirectional LSTMs trained as language models. Unlike static embeddings, ELMo representations varied based on context, capturing polysemy and complex linguistic features. ELMo demonstrated the power of pre-training and fine-tuning, significantly improving performance across diverse NLP tasks. It was a crucial step toward modern contextualized language models and transfer learning in NLP.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2018</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2018</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="GPT (Generative Pre-Training) at OpenAI" alt="GPT (Generative Pre-Training) at OpenAI" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/openai.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for GPT (Generative Pre-Training)">Details</button><h3 class="font-semibold text-lg">GPT (Generative Pre-Training)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">OpenAI</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever</span></div><p class="text-xs mt-1">Paper: <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Improving Language Understanding by Generative Pre-Training</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/openai/finetune-transformer-lm" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">finetune-transformer-lm</a></p><p class="mt-2 whitespace-pre-line">GPT introduced a two-stage approach: unsupervised pre-training of a transformer language model on large text corpora, followed by supervised fine-tuning on specific tasks. This demonstrated that language models could learn general representations useful across many tasks. GPT showed that pre-training could significantly reduce the labeled data required for downstream tasks, establishing the pre-train-then-fine-tune paradigm that dominated subsequent NLP research.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2018</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2018</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="BERT (Bidirectional Encoder Representations from Transformers) at Google" alt="BERT (Bidirectional Encoder Representations from Transformers) at Google" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/google.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for BERT (Bidirectional Encoder Representations from Transformers)">Details</button><h3 class="font-semibold text-lg">BERT (Bidirectional Encoder Representations from Transformers)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Google</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/google-research/bert" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">bert</a></p><p class="mt-2 whitespace-pre-line">BERT pre-trained bidirectional transformers using masked language modeling and next sentence prediction. Unlike previous unidirectional models, BERT jointly conditioned on both left and right context in all layers. BERT achieved state-of-the-art results across eleven NLP tasks and demonstrated that deeply bidirectional pre-training was crucial for language understanding. BERT became the foundation for numerous downstream applications and variants.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2018</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2018</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Mixed Precision Training at NVIDIA" alt="Mixed Precision Training at NVIDIA" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/nvidia.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Mixed Precision Training">Details</button><h3 class="font-semibold text-lg">Mixed Precision Training</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">NVIDIA</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Olaf Klauser, Andrew Kraljevic, Chris Paine, Naveen Satish, Michael Wu</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1710.03740.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Mixed Precision Training</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/NVIDIA/apex" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">apex</a></p><p class="mt-2 whitespace-pre-line">Micikevicius et al. showed how to safely train deep networks using half-precision (FP16) arithmetic while preserving full-precision accuracy. By keeping FP32 master weights, accumulating gradients in FP32, and using loss scaling to avoid underflow, they demonstrated 2–3× speedups on NVIDIA Tensor Cores without sacrificing convergence. Mixed precision became the standard recipe for large-scale transformer training, enabling today’s models to fit within GPU memory budgets.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2019</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2019</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="GPT-2 at OpenAI" alt="GPT-2 at OpenAI" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/openai.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for GPT-2">Details</button><h3 class="font-semibold text-lg">GPT-2</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">OpenAI</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever</span></div><p class="text-xs mt-1">Paper: <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Language Models are Unsupervised Multitask Learners</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/openai/gpt-2" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">gpt-2</a></p><p class="mt-2 whitespace-pre-line">GPT-2 scaled up the original GPT to 1.5 billion parameters and trained on a larger, more diverse dataset. It demonstrated that language models could perform many tasks zero-shot without fine-tuning by simply conditioning on appropriate prompts. GPT-2 showed strong performance on diverse tasks including translation, summarization, and question answering, suggesting that with sufficient scale and data, language models naturally learn multitask capabilities.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2019</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2019</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="T5 (Text-to-Text Transfer Transformer) at Google" alt="T5 (Text-to-Text Transfer Transformer) at Google" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/google.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for T5 (Text-to-Text Transfer Transformer)">Details</button><h3 class="font-semibold text-lg">T5 (Text-to-Text Transfer Transformer)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Google</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1910.10683.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/google-research/text-to-text-transfer-transformer" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">text-to-text-transfer-transformer</a></p><p class="mt-2 whitespace-pre-line">T5 unified all NLP tasks into a text-to-text format where both inputs and outputs are text strings. It systematically explored transfer learning techniques including pre-training objectives, architectures, datasets, and fine-tuning methods. T5&#x27;s encoder-decoder architecture and comprehensive evaluation provided insights into what makes transfer learning effective. The unified framework simplified multi-task learning and became influential for instruction-following models.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2019</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2019</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="The Bitter Lesson at University of Alberta, DeepMind" alt="The Bitter Lesson at University of Alberta, DeepMind" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/alberta.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for The Bitter Lesson">Details</button><h3 class="font-semibold text-lg">The Bitter Lesson</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">University of Alberta, DeepMind</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Richard Sutton</span></div><p class="text-xs mt-1">Paper: <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">The Bitter Lesson (Essay)</a></p><p class="mt-2 whitespace-pre-line">The Bitter Lesson essay argued that general methods leveraging computation consistently outperform approaches that rely on human knowledge in the long run. Sutton observed that search and learning, when given sufficient computation, surpass hand-crafted features and domain expertise. This philosophical perspective influenced the field to focus on scalable learning methods rather than encoding human knowledge, providing intellectual foundation for the scaling paradigm in modern AI.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2020</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2020</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Scaling Laws for Neural Language Models at OpenAI" alt="Scaling Laws for Neural Language Models at OpenAI" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/openai.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Scaling Laws for Neural Language Models">Details</button><h3 class="font-semibold text-lg">Scaling Laws for Neural Language Models</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">OpenAI</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2001.08361.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Scaling Laws for Neural Language Models</a></p><p class="mt-2 whitespace-pre-line">This work empirically demonstrated that language model performance scales as power-laws with model size, dataset size, and compute budget. The research showed predictable relationships between these factors and suggested optimal allocation strategies. These scaling laws provided quantitative guidance for training large models and predicted that simply scaling up models would continue to yield improvements, influencing subsequent investment in large-scale model development.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2020</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2020</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="GPT-3 at OpenAI" alt="GPT-3 at OpenAI" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/openai.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for GPT-3">Details</button><h3 class="font-semibold text-lg">GPT-3</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">OpenAI</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2005.14165.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Language Models are Few-Shot Learners</a></p><p class="mt-2 whitespace-pre-line">GPT-3 scaled transformers to 175 billion parameters, demonstrating that language models could perform diverse tasks with few-shot, one-shot, or zero-shot learning from prompts alone. It showed impressive performance on translation, question-answering, arithmetic, and novel word usage without gradient updates. GPT-3 revealed that with sufficient scale, language models develop broad capabilities and sparked widespread interest in large language models and prompt engineering.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2020</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2020</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="ZeRO (Zero Redundancy Optimizer) at Microsoft" alt="ZeRO (Zero Redundancy Optimizer) at Microsoft" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/microsoft.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for ZeRO (Zero Redundancy Optimizer)">Details</button><h3 class="font-semibold text-lg">ZeRO (Zero Redundancy Optimizer)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Microsoft</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, Yuxiong He</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/1910.02054.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/microsoft/DeepSpeed" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">DeepSpeed</a></p><p class="mt-2 whitespace-pre-line">ZeRO eliminated memory redundancies in data-parallel distributed training by partitioning optimizer states, gradients, and parameters across devices rather than replicating them. ZeRO enabled training models with trillions of parameters by dramatically reducing per-device memory requirements while maintaining computational efficiency. This optimization became crucial for training large language models and is implemented in DeepSpeed, enabling the scale of models like GPT-3 and beyond.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2021</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2021</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="RoFormer: Rotary Position Embedding (RoPE) at Zhuiyi Technology" alt="RoFormer: Rotary Position Embedding (RoPE) at Zhuiyi Technology" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/zhuiyi.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for RoFormer: Rotary Position Embedding (RoPE)">Details</button><h3 class="font-semibold text-lg">RoFormer: Rotary Position Embedding (RoPE)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Zhuiyi Technology</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, Yunfeng Liu</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2104.09864.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">RoFormer: Enhanced Transformer with Rotary Position Embedding</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/ZhuiyiTechnology/roformer" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">roformer</a></p><p class="mt-2 whitespace-pre-line">Rotary Position Embedding (RoPE) encodes position information by rotating word embeddings based on their absolute positions, while naturally encoding relative position information through the rotation properties. RoPE provided better extrapolation to longer sequences than previous position encoding methods while being computationally efficient. It was adopted by influential models including PaLM, LLaMA, and many other modern LLMs, becoming a preferred position encoding technique.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2021</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2021</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="LoRA: Low-Rank Adaptation of Large Language Models at Microsoft" alt="LoRA: Low-Rank Adaptation of Large Language Models at Microsoft" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/microsoft.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for LoRA: Low-Rank Adaptation of Large Language Models">Details</button><h3 class="font-semibold text-lg">LoRA: Low-Rank Adaptation of Large Language Models</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Microsoft</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2106.09685.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">LoRA: Low-Rank Adaptation of Large Language Models</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/microsoft/LoRA" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">LoRA</a></p><p class="mt-2 whitespace-pre-line">LoRA enabled efficient fine-tuning of large language models by training low-rank decomposition matrices that are added to frozen pre-trained weights. This reduced trainable parameters by 10,000x and memory requirements by 3x while maintaining or exceeding full fine-tuning performance. LoRA made it practical to customize large models for specific tasks with limited compute resources, democratizing access to fine-tuning and enabling rapid adaptation of foundation models.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2022</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2022</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="InstructGPT at OpenAI" alt="InstructGPT at OpenAI" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/openai.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for InstructGPT">Details</button><h3 class="font-semibold text-lg">InstructGPT</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">OpenAI</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, Ryan Lowe</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2203.02155.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Training Language Models to Follow Instructions with Human Feedback</a></p><p class="mt-2 whitespace-pre-line">InstructGPT fine-tuned GPT-3 using supervised learning on human-written demonstrations followed by reinforcement learning from human feedback. Despite having 100x fewer parameters, InstructGPT outputs were preferred to GPT-3 outputs. The model showed improvements in truthfulness, helpfulness, and reduced toxicity. InstructGPT demonstrated that alignment with human preferences through RLHF was crucial for making language models useful and safe, establishing the approach used in ChatGPT.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2022</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2022</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Chain-of-Thought Prompting at Google Research" alt="Chain-of-Thought Prompting at Google Research" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/google.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Chain-of-Thought Prompting">Details</button><h3 class="font-semibold text-lg">Chain-of-Thought Prompting</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Google Research</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2201.11903.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a></p><p class="mt-2 whitespace-pre-line">Chain-of-thought prompting enabled language models to solve complex reasoning tasks by generating intermediate reasoning steps before arriving at final answers. Simply adding a few examples with reasoning chains dramatically improved performance on arithmetic, commonsense, and symbolic reasoning tasks. This technique revealed emergent reasoning capabilities in large models and demonstrated that prompting strategies could unlock latent abilities without additional training.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2022</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2022</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="FlashAttention at Stanford University" alt="FlashAttention at Stanford University" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/stanford.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for FlashAttention">Details</button><h3 class="font-semibold text-lg">FlashAttention</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Stanford University</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, Christopher Ré</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2205.14135.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/Dao-AILab/flash-attention" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">flash-attention</a></p><p class="mt-2 whitespace-pre-line">FlashAttention optimized the attention mechanism by accounting for GPU memory hierarchy, using tiling to reduce data movement between GPU memory levels. This IO-aware algorithm achieved exact attention with significantly reduced memory usage and 2-4x speedup compared to standard implementations. FlashAttention enabled training transformers with much longer context lengths and became widely adopted, fundamentally improving the efficiency of transformer models.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2022</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2022</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Constitutional AI: Harmlessness from AI Feedback at Anthropic" alt="Constitutional AI: Harmlessness from AI Feedback at Anthropic" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/anthropic.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Constitutional AI: Harmlessness from AI Feedback">Details</button><h3 class="font-semibold text-lg">Constitutional AI: Harmlessness from AI Feedback</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Anthropic</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, Noemi Mercado, Nova DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, Sheer El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly, Tom Henighan, Tristan Hume, Samuel R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, Jared Kaplan</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2212.08073.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Constitutional AI: Harmlessness from AI Feedback</a></p><p class="mt-2 whitespace-pre-line">Constitutional AI introduced a method for training harmless AI assistants using AI-generated feedback based on a set of principles (a &#x27;constitution&#x27;) rather than relying solely on human feedback. The model critiques and revises its own responses according to constitutional principles, then learns from these self-improvements. This approach reduced reliance on human labelers for harmlessness training while making the values guiding AI behavior more transparent and debuggable.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2023</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2023</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Direct Preference Optimization (DPO) at Stanford University" alt="Direct Preference Optimization (DPO) at Stanford University" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/stanford.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Direct Preference Optimization (DPO)">Details</button><h3 class="font-semibold text-lg">Direct Preference Optimization (DPO)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Stanford University</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, Chelsea Finn</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2305.18290.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Direct Preference Optimization: Your Language Model is Secretly a Reward Model</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/eric-mitchell/direct-preference-optimization" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">direct-preference-optimization</a></p><p class="mt-2 whitespace-pre-line">DPO simplified preference learning by directly optimizing language models on human preferences without requiring a separate reward model or reinforcement learning. It reformulated RLHF as a classification problem over preference pairs, making training more stable and efficient. DPO achieved comparable or better results than RLHF while being simpler to implement and tune, becoming a popular alternative for aligning language models with human preferences.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2023</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2023</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="QLoRA: Efficient Fine-Tuning of Quantized LLMs at University of Washington" alt="QLoRA: Efficient Fine-Tuning of Quantized LLMs at University of Washington" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/washington.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for QLoRA: Efficient Fine-Tuning of Quantized LLMs">Details</button><h3 class="font-semibold text-lg">QLoRA: Efficient Fine-Tuning of Quantized LLMs</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">University of Washington</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, Luke Zettlemoyer</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2305.14314.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">QLoRA: Efficient Finetuning of Quantized LLMs</a></p><p class="text-xs mt-1"><span>GitHub repo:<!-- --> </span><a href="https://github.com/artidoro/qlora" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">qlora</a></p><p class="mt-2 whitespace-pre-line">QLoRA combined quantization with LoRA to enable fine-tuning of extremely large models on consumer hardware. It quantized the base model to 4-bit precision while using LoRA adapters in higher precision, maintaining full fine-tuning performance. QLoRA made it possible to fine-tune a 65B parameter model on a single GPU with 48GB memory, dramatically democratizing access to fine-tuning large language models and enabling researchers with limited resources to customize state-of-the-art models.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2024</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2024</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Mixture-of-Experts (MoE) and Test-Time Compute Scaling at Google, xAI, DeepSeek" alt="Mixture-of-Experts (MoE) and Test-Time Compute Scaling at Google, xAI, DeepSeek" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/google.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Mixture-of-Experts (MoE) and Test-Time Compute Scaling">Details</button><h3 class="font-semibold text-lg">Mixture-of-Experts (MoE) and Test-Time Compute Scaling</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Google, xAI, DeepSeek</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, William El Sayed</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2401.04088.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Mixtral of Experts</a></p><p class="mt-2 whitespace-pre-line">Modern Mixture-of-Experts architectures like Mixtral, Grok, and DeepSeek-V2 combined sparse routing with test-time compute scaling, allowing models to dynamically allocate computation based on task difficulty. These architectures activated only a subset of parameters per token while maintaining large total capacity, achieving better performance-per-compute ratios. The combination with test-time scaling, where models use more computation for harder problems, represented a shift toward more efficient and adaptive AI systems.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2024</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2024</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Layer Dropping and Progressive Pruning (TrimLLM) at Northeastern University, Indiana University Bloomington, University of Connecticut, University of Massachusetts Dartmouth, North Carolina State University" alt="Layer Dropping and Progressive Pruning (TrimLLM) at Northeastern University, Indiana University Bloomington, University of Connecticut, University of Massachusetts Dartmouth, North Carolina State University" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/northeastern.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Layer Dropping and Progressive Pruning (TrimLLM)">Details</button><h3 class="font-semibold text-lg">Layer Dropping and Progressive Pruning (TrimLLM)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Northeastern University, Indiana University Bloomington, University of Connecticut, University of Massachusetts Dartmouth, North Carolina State University</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Lei Lu, Zhepeng Wang, Runyu Peng, Mengbing Wang, Fangyi Zhu, Zilong Wang, Hong Xu, Shangguang Wang</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2406.02629.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">TrimLLM: Progressive Layer Dropping for Efficient LLM Inference</a></p><p class="mt-2 whitespace-pre-line">Layer dropping and progressive pruning techniques enabled efficient inference by selectively skipping or removing transformer layers based on input characteristics or layer importance. Research showed that many layers in large language models are redundant for certain tasks, and adaptive layer selection could maintain performance while reducing computation. These techniques became important for deploying large models in resource-constrained environments and improving inference efficiency.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2024</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2024</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Multimodal Secure Alignment at Carnegie Mellon University, University of Washington" alt="Multimodal Secure Alignment at Carnegie Mellon University, University of Washington" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/cmu.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Multimodal Secure Alignment">Details</button><h3 class="font-semibold text-lg">Multimodal Secure Alignment</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Carnegie Mellon University, University of Washington</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Xuguang Wang, Xin Eric Wang</span></div><p class="text-xs mt-1">Paper: <a href="https://arxiv.org/pdf/2404.12464.pdf" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Defending Against Jailbreak Attacks in Multimodal Language Models</a></p><p class="mt-2 whitespace-pre-line">Multimodal secure alignment addresses unique safety challenges when language models process multiple modalities (text, images, audio). Research revealed that multimodal models could be more vulnerable to jailbreaks through adversarial images or cross-modal attacks. New alignment techniques were developed to ensure consistent safety behavior across modalities, including modality-specific safety layers and cross-modal consistency checking. This work became critical as vision-language models like GPT-4V and Gemini became widely deployed.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2025</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2025</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Chain-of-Thought Monitorability at Google DeepMind, Anthropic" alt="Chain-of-Thought Monitorability at Google DeepMind, Anthropic" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/deepmind.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Chain-of-Thought Monitorability">Details</button><h3 class="font-semibold text-lg">Chain-of-Thought Monitorability</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Google DeepMind, Anthropic</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Scott Emmons, Erik Jenner, David K. Elson, Rif A. Saurous, Senthooran Rajamanoharan, Heng Chen, Irhum Shafkat, Rohin Shah</span></div><p class="text-xs mt-1">Paper: <a href="https://doi.org/10.48550/arXiv.2507.05246" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">When Chain of Thought is Necessary, Language Models Struggle to Evade Monitors</a></p><p class="mt-2 whitespace-pre-line">This work reframed chain-of-thought (CoT) safety monitoring around monitorability rather than faithfulness, distinguishing CoT-as-rationalization from CoT-as-computation. By making harmful behaviors require multi-step reasoning, the authors forced models to expose their plans and showed that CoT monitoring can detect severe risks unless attackers receive substantial assistance. The paper also offered stress-testing guidelines, concluding that CoT monitoring remains a valuable, if imperfect, layer of defense that warrants active protection and continual evaluation.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2025</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2025</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Critical Representation Fine-Tuning (CRFT) at Zhejiang University, Alibaba Cloud Computing" alt="Critical Representation Fine-Tuning (CRFT) at Zhejiang University, Alibaba Cloud Computing" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/zhejiang_university.svg"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Critical Representation Fine-Tuning (CRFT)">Details</button><h3 class="font-semibold text-lg">Critical Representation Fine-Tuning (CRFT)</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Zhejiang University, Alibaba Cloud Computing</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Chenxi Huang, Shaotian Yan, Liang Xie, Binbin Lin, Sinan Fan, Yue Xin, Deng Cai, Chen Shen, Jieping Ye</span></div><p class="text-xs mt-1">Paper: <a href="https://doi.org/10.48550/arXiv.2507.10085" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning</a></p><p class="mt-2 whitespace-pre-line">CRFT extends Representation Fine-Tuning by identifying &quot;critical&quot; hidden representations that aggregate or gate reasoning signals, then editing them in a low-rank subspace while freezing the base LLaMA or Mistral weights. Information-flow analysis selects these high-leverage states, enabling large CoT accuracy gains across eight arithmetic and commonsense benchmarks as well as sizeable one-shot improvements. The work highlights that representation-level PEFT can unlock better reasoning without touching most model parameters.</p></div></div></div></div><div class="mb-10 Timeline-module__msIhgq__rowGrid"><div class="Timeline-module__msIhgq__yearColumn text-sm">2025</div><div class="flex Timeline-module__msIhgq__circles"><div class="flex items-center w-3 h-3 bg-sky-500 rounded-full border-5 border-white z-30"></div></div><div class="Timeline-module__msIhgq__contentColumn w-full"><div class="Timeline-module__msIhgq__yearMobile text-sm mb-2">2025</div><div class="flex items-start gap-4"><div class="flex-shrink-0 Timeline-module__msIhgq__logoContainer"><img title="Mechanistic OOCR Steering Vectors at Massachusetts Institute of Technology, Independent Researchers" alt="Mechanistic OOCR Steering Vectors at Massachusetts Institute of Technology, Independent Researchers" loading="lazy" width="80" height="80" decoding="async" data-nimg="1" class="Timeline-module__msIhgq__logoImage" style="color:transparent" src="/img/ml/mit.png"/></div><div class="relative z-20 text-box rounded-lg shadow w-full Timeline-module__msIhgq__card"><button type="button" class="absolute top-3 right-3 text-xs font-medium px-2 py-1 rounded transition-colors text-sky-600 dark:text-sky-400 border border-sky-200 dark:border-sky-800 hover:bg-sky-50 dark:hover:bg-slate-900" aria-label="View more details for Mechanistic OOCR Steering Vectors">Details</button><h3 class="font-semibold text-lg">Mechanistic OOCR Steering Vectors</h3><p class="text-sm text-gray-600 dark:text-gray-400 mt-1">Massachusetts Institute of Technology, Independent Researchers</p><div class="text-sm text-gray-600 dark:text-gray-400 mt-1"><span>Atticus Wang, Joshua Engels, Oliver Clive-Griffin, Senthooran Rajamanoharan, Neel Nanda</span></div><p class="text-xs mt-1">Paper: <a href="https://doi.org/10.48550/arXiv.2507.08218" target="_blank" rel="noopener noreferrer" class="text-sky-600 dark:text-sky-400 hover:underline">Simple Mechanistic Explanations for Out-Of-Context Reasoning</a></p><p class="mt-2 whitespace-pre-line">This study dissects out-of-context reasoning (OOCR) and finds that many reported cases arise because LoRA fine-tuning effectively adds a constant steering vector that pushes models toward latent concepts. By extracting or directly training such steering vectors, the authors reproduce OOCR across risky/safe decision, function, location, and backdoor benchmarks, showing that unconditional steering can even implement conditional behaviors. The results provide a simple mechanistic account of why fine-tuned LLMs can generalize far beyond their training distribution and highlight the alignment implications of steering-vector interventions.</p></div></div></div></div></div></section></main><!--$--><!--/$--><footer><p>© <!-- -->2025<!-- --> Henrik Nordberg</p></footer><script src="/_next/static/chunks/2e777329c8f64894.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[58195,[\"/_next/static/chunks/dc293e429f126484.js\"],\"default\"]\n3:I[62863,[\"/_next/static/chunks/dc293e429f126484.js\"],\"default\"]\n4:I[39756,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n5:I[37457,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n6:I[50535,[\"/_next/static/chunks/dc293e429f126484.js\",\"/_next/static/chunks/35d043138a0d6b40.js\"],\"default\"]\nc:I[68027,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"default\"]\n:HL[\"/_next/static/chunks/709d76917318ea58.css\",\"style\"]\n:HL[\"/_next/static/chunks/0c61c8691d9d95a7.css\",\"style\"]\n7:T4ae,To reproduce Rosenblatt’s perceptron, start with a set of linearly separable training examples (e.g., 2D points labeled positive or negative). Initialize a weight vector and bias to zero (or small random values). For each training sample x with label y ∈ {−1, +1}, compute the activation a = w·x + b. If y·a ≤ 0 (the sample is misclassified), update the parameters with the perceptron rule: w ← w + η·y·x and b ← b + η·y, where η is a small learning rate (often 1.0 for the classic algorithm). Sweep through the dataset repeatedly until all samples are correctly classified or a maximum number of passes is reached. In code, this translates to a tight loop over the dataset with a dot product, a sign check, and in-place vector additions. To deploy the model, classify new inputs by computing w·x + b and returning the sign. Extensions include using homogeneous coordinates to fold the bias into the weight vector, shuffling examples between epochs to avoid cyclic updates, and visualizing the decision boundary w to confirm convergence. Although simple, this implementation demonstrates online learning, margin intuition, and the foundations of modern gradient-based training."])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"n7JqkWY1I6Zu1oUapzzgq\",\"c\":[\"\",\"p\",\"ml\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"p\",{\"children\":[\"ml\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/709d76917318ea58.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/dc293e429f126484.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"children\":[[\"$\",\"header\",null,{\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"$L3\",null,{}]]}],[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"footer\",null,{\"children\":[\"$\",\"p\",null,{\"children\":[\"© \",2025,\" Henrik Nordberg\"]}]}]]}]}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"main\",null,{\"children\":[[\"$\",\"div\",null,{\"className\":\"text-center pt-8 pb-4\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold\",\"children\":\"History of Machine Learning \u0026 LLMs\"}],[\"$\",\"p\",null,{\"className\":\"text-lg text-gray-600 dark:text-gray-400\",\"children\":\"Disclaimer: I used various LLMs to generate the data for this timeline.\"}]]}],[\"$\",\"$L6\",null,{\"items\":[{\"id\":\"Perceptron\",\"period\":\"1957\",\"title\":\"Perceptron\",\"org\":\"Cornell Aeronautical Laboratory\",\"location\":\"https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf\",\"paperTitle\":\"The Perceptron: A Perceiving and Recognizing Automaton\",\"authors\":[\"Frank Rosenblatt\"],\"description\":\"The Perceptron was the first model that could learn the weights defining categories given examples from each category. It established the foundation for artificial neural networks by introducing a learning algorithm that could automatically adjust connection weights. The perceptron demonstrated that machines could learn from experience, marking a fundamental breakthrough in machine learning.\",\"icon\":\"ml/cornell.svg\",\"details\":\"$7\"},{\"id\":\"Neocognitron\",\"period\":\"1980\",\"title\":\"Neocognitron\",\"org\":\"NHK Science \u0026 Technical Research Laboratories\",\"location\":\"https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf\",\"paperTitle\":\"Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position\",\"authors\":[\"Kunihiko Fukushima\"],\"description\":\"The Neocognitron was a hierarchical, multilayered neural network inspired by the visual cortex. It introduced the concepts of S-cells (simple cells) and C-cells (complex cells) arranged in a hierarchy, allowing for position-invariant pattern recognition. This architecture laid the groundwork for modern convolutional neural networks and demonstrated that local feature extraction combined with spatial pooling could achieve robust visual recognition.\",\"icon\":\"ml/nhk.svg\",\"details\":\"To prototype a Neocognitron, stack multiple stages made of S-layers (convolutions with learned kernels plus nonlinear activation) followed by C-layers (local pooling/averaging with competition). Begin with small receptive fields (e.g., 5×5 filters) and progressively increase the number of feature maps per stage. During training, expose the network to input patterns translated across the visual field; learning adjusts S-layer kernels via unsupervised Hebbian/competitive rules, while C-layers perform max or average pooling to promote shift invariance. A modern replication can approximate the original by building a CNN that alternates conv → ReLU → local pooling, but to stay faithful include winner-take-all inhibition on S-cells and normalize responses within C-cells. Evaluate by feeding handwritten digits or symbols at various positions and verifying that final feature maps remain stable under shifts.\"},{\"id\":\"Backpropagation\",\"period\":\"1986\",\"title\":\"Backpropagation\",\"org\":\"University of California San Diego, Carnegie Mellon University, University of Toronto\",\"location\":\"https://www.nature.com/articles/323533a0\",\"paperTitle\":\"Learning Representations by Back-propagating Errors\",\"authors\":[\"David E. Rumelhart\",\"Geoffrey E. Hinton\",\"Ronald J. Williams\"],\"description\":\"Backpropagation provided an efficient method for training multi-layer neural networks by computing gradients through the chain rule. This algorithm enabled the training of deep networks by propagating error signals backwards through layers, allowing hidden units to learn internal representations. Backpropagation became the workhorse of neural network training and remains fundamental to modern deep learning.\",\"icon\":\"ml/ucsd.svg\",\"details\":\"Implement backprop by defining a feedforward network with differentiable layers (affine + activation). During the forward pass compute activations for each layer and the loss L(ŷ, y). For the backward pass, initialize δ at the output layer as ∂L/∂ŷ · σ′(z). Propagate gradients layer-by-layer using δᵗ = (Wᵗ⁺¹)ᵗ δ⁺¹ ⊙ σ′(zᵗ), and accumulate weight gradients ΔWᵗ = δᵗ (aᵗ⁻¹)ᵗ, Δbᵗ = δᵗ. Update parameters with learning rate η: Wᵗ ← Wᵗ − η·ΔWᵗ, bᵗ ← bᵗ − η·Δbᵗ. To stabilize training, use mini-batches, momentum, or adaptive optimizers. A simple reference implementation fits an MLP (784-128-64-10) on MNIST, using ReLU hidden units and softmax-cross-entropy output. Backprop generalizes to any computation graph: store intermediate values during forward pass, define local derivatives, and traverse the graph in reverse topological order to accumulate gradients.\"},{\"id\":\"LSTM\",\"period\":\"1997\",\"title\":\"Long Short-Term Memory (LSTM)\",\"org\":\"Technische Universität München\",\"location\":\"https://deeplearning.cs.cmu.edu/S23/document/readings/LSTM.pdf\",\"paperTitle\":\"Long Short-Term Memory\",\"authors\":[\"Sepp Hochreiter\",\"Jürgen Schmidhuber\"],\"description\":\"LSTM addressed the vanishing gradient problem in recurrent neural networks by introducing memory cells with gating mechanisms. The architecture uses input, output, and forget gates to control information flow, enabling networks to learn long-term dependencies. LSTM became the dominant architecture for sequence modeling tasks including speech recognition, machine translation, and time series prediction before the transformer era.\",\"icon\":\"ml/tum.gif\",\"details\":\"To code an LSTM layer, maintain cell state cₜ and hidden state hₜ. For each timestep xₜ, compute gates: iₜ = σ(Wᵢxₜ + Uᵢhₜ₋₁ + bᵢ), fₜ = σ(W_fxₜ + U_fhₜ₋₁ + b_f), oₜ = σ(Wₒxₜ + Uₒhₜ₋₁ + bₒ), ĝₜ = tanh(W_gxₜ + U_ghₜ₋₁ + b_g). Update cell state cₜ = fₜ ⊙ cₜ₋₁ + iₜ ⊙ ĝₜ and hidden state hₜ = oₜ ⊙ tanh(cₜ). Initialize c₀, h₀ to zeros. Backpropagation through time applies chain rule across timesteps, so cache gate activations and cell states to compute gradients efficiently. Practical tips: clip gradients to prevent explosion, use dropout on recurrent connections (e.g., variational dropout), and batch sequences with padding + masking. A minimal example trains an LSTM language model: embed tokens, pass through LSTM, project to vocabulary logits, compute cross-entropy, and optimize with Adam.\"},{\"id\":\"LeNet\",\"period\":\"1998\",\"title\":\"Convolutional Neural Networks (LeNet)\",\"org\":\"AT\u0026T Bell Laboratories\",\"location\":\"http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf\",\"paperTitle\":\"Gradient-Based Learning Applied to Document Recognition\",\"authors\":[\"Yann LeCun\",\"Léon Bottou\",\"Yoshua Bengio\",\"Patrick Haffner\"],\"description\":\"LeNet introduced a practical convolutional neural network architecture for document recognition. It combined convolutional layers for local feature extraction, pooling for spatial invariance, and fully connected layers for classification. This architecture demonstrated that CNNs could be trained end-to-end using backpropagation and achieved state-of-the-art results on handwritten digit recognition, establishing the blueprint for modern computer vision systems.\",\"icon\":\"ml/bell_labs.svg\",\"details\":\"Recreate LeNet-5 with the original topology: input 32×32 grayscale image, conv1 (6 filters, 5×5, tanh) → subsampling (avg pooling, stride 2) → conv2 (16 filters, 5×5) → subsampling → conv3 (120 filters, 5×5) → flatten → FC1 (84 units) → FC2 (10 units, softmax). Use zero padding to preserve spatial dimensions in early layers. Train on centered MNIST digits, optionally augment with elastic distortions. Optimization: stochastic gradient descent with learning rate ≈0.01, momentum 0.9, and LeCun’s original weight normalization (fan-in scaling). Implement average pooling as learned subsampling (multiply by trainable weights and bias) if you want historical fidelity; otherwise max pooling works as a simplification. Evaluate by measuring test accuracy and visualizing feature maps to confirm hierarchical feature extraction.\"},{\"id\":\"Neural_Probabilistic_LM\",\"period\":\"2003\",\"title\":\"The Neural Probabilistic Language Model\",\"org\":\"Université de Montréal\",\"location\":\"https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf\",\"paperTitle\":\"A Neural Probabilistic Language Model\",\"authors\":[\"Yoshua Bengio\",\"Réjean Ducharme\",\"Pascal Vincent\",\"Christian Jauvin\"],\"description\":\"The Neural Probabilistic Language Model addressed the curse of dimensionality in language modeling by learning distributed representations for words. It introduced the idea that similar words would have similar vector representations, allowing the model to generalize to unseen word sequences. This foundational work pioneered the use of neural networks for language modeling and word embeddings, directly inspiring Word2Vec and modern language models.\",\"icon\":\"ml/montreal.png\",\"details\":\"Implement Bengio et al.’s model by (1) building a vocabulary V and mapping each word to a D-dimensional embedding vector; (2) concatenating embeddings for the previous n words to form context vector h; (3) passing h through a hidden layer with tanh and projecting to a |V|-dimensional softmax to produce next-word probabilities. Training minimizes negative log-likelihood using SGD. To improve efficiency, precompute and cache embeddings, use weight sharing for input/output matrices, and apply techniques like importance sampling or noise-contrastive estimation when V is large. Evaluation involves perplexity on held-out text: lower perplexity indicates better modeling of unseen sequences. This structure lays the groundwork for modern embedding layers and feedforward language models.\"},{\"id\":\"ImageNet\",\"period\":\"2009\",\"title\":\"ImageNet Dataset\",\"org\":\"Princeton University\",\"location\":\"https://www.image-net.org/static_files/papers/imagenet_cvpr09.pdf\",\"paperTitle\":\"ImageNet: A Large-Scale Hierarchical Image Database\",\"authors\":[\"Jia Deng\",\"Wei Dong\",\"Richard Socher\",\"Li-Jia Li\",\"Kai Li\",\"Li Fei-Fei\"],\"description\":\"ImageNet created a large-scale dataset with over 14 million labeled images across thousands of categories, organized hierarchically using WordNet. The annual ImageNet Large Scale Visual Recognition Challenge (ILSVRC) became the premier benchmark for computer vision. ImageNet's scale and diversity enabled the training of deep neural networks and catalyzed the deep learning revolution, particularly with AlexNet's breakthrough in 2012.\",\"icon\":\"ml/princeton.png\",\"details\":\"To work with ImageNet, download the ILSVRC subset (≈1.2M training images across 1,000 classes). Preprocess by resizing images so the shorter side is 256 px, then apply random 224×224 crops, horizontal flips, and mean/std normalization. Construct a data pipeline that shuffles, augments, and batches images efficiently (e.g., tf.data or PyTorch DataLoader with multiworkers). For evaluation, use center-crop or ten-crop testing. Organize labels according to WordNet synsets to maintain the semantic hierarchy. Training a modern classifier (ResNet, ViT) on ImageNet provides a standard benchmark; fine-tuning those weights on downstream tasks leverages ImageNet’s rich visual priors.\"},{\"id\":\"Xavier\",\"period\":\"2010\",\"title\":\"Xavier/Glorot Initialization\",\"org\":\"Université de Montréal\",\"location\":\"https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf\",\"paperTitle\":\"Understanding the Difficulty of Training Deep Feedforward Neural Networks\",\"authors\":[\"Xavier Glorot\",\"Yoshua Bengio\"],\"description\":\"Xavier initialization provided a principled method for initializing neural network weights to maintain consistent variance of activations and gradients across layers. By scaling initial weights based on the number of input and output connections, it prevented vanishing or exploding gradients during training. This simple but crucial technique enabled the training of much deeper networks and remains a standard practice in deep learning.\",\"icon\":\"ml/montreal.png\",\"details\":\"Apply Xavier (Glorot) initialization when creating dense or tanh-activated layers: draw weights W ∼ U[−√(6/(fan_in+fan_out)), √(6/(fan_in+fan_out))] for uniform, or W ∼ N(0, 2/(fan_in+fan_out)) for normal. fan_in is the number of input connections, fan_out the number of output connections. Biases typically initialize to zero. For ReLU layers, switch to He initialization (variance 2/fan_in). Most frameworks expose helpers (e.g., torch.nn.init.xavier_uniform_) but understanding the formula lets you customize for convolutions (where fan counts depend on kernel size × channels). Proper initialization stabilizes early training by keeping signal variances consistent across layers.\"},{\"id\":\"ReLU\",\"period\":\"2010\",\"title\":\"Rectified Linear Unit (ReLU) Activation\",\"org\":\"University of Toronto\",\"location\":\"https://www.cs.toronto.edu/~fritz/absps/reluICML.pdf\",\"paperTitle\":\"Rectified Linear Units Improve Restricted Boltzmann Machines\",\"authors\":[\"Vinod Nair\",\"Geoffrey E. Hinton\"],\"description\":\"ReLU introduced a simple non-saturating activation function f(x) = max(0, x) that addressed the vanishing gradient problem of sigmoid and tanh activations. ReLU enabled faster training, reduced computational cost, and induced sparsity in neural networks. Despite its simplicity, ReLU became the default activation function for deep neural networks and enabled the training of much deeper architectures.\",\"icon\":\"ml/toronto.svg\",\"details\":\"To incorporate ReLU, replace sigmoid/tanh activations with f(x)=max(0,x) after linear or convolutional layers. In code, this is a single-element-wise operation (e.g., torch.nn.ReLU(inplace=True)). Combine with He initialization and learning rate schedules to ensure stable gradients. Mitigate “dying ReLU” by using LeakyReLU or ELU if many neurons output zero; batch norm also helps keep activations in a healthy range. Monitor sparsity (percentage of zeros) to confirm the intended regularizing effect. ReLU’s piecewise-linear behavior makes backprop simple: the derivative is 1 for x\u003e0 and 0 otherwise.\"},{\"id\":\"AlexNet\",\"period\":\"2012\",\"title\":\"AlexNet\",\"org\":\"University of Toronto\",\"location\":\"https://proceedings.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\",\"paperTitle\":\"ImageNet Classification with Deep Convolutional Neural Networks\",\"authors\":[\"Alex Krizhevsky\",\"Ilya Sutskever\",\"Geoffrey E. Hinton\"],\"description\":\"AlexNet won the ImageNet 2012 competition with a significant margin, demonstrating that deep convolutional networks trained with GPUs could dramatically outperform traditional computer vision methods. The architecture combined ReLU activations, dropout regularization, data augmentation, and GPU training. AlexNet's success marked the beginning of the deep learning era and sparked intense interest in neural networks across academia and industry.\",\"icon\":\"ml/toronto.svg\",\"details\":\"Recreate AlexNet with five convolutional layers followed by three fully connected layers: Conv1 (11×11 stride 4, 96 filters) → LRN → max pool; Conv2 (5×5, 256 filters split across GPUs) → LRN → max pool; Conv3 (3×3, 384) → Conv4 (3×3, 384) → Conv5 (3×3, 256) → max pool; FC6 (4096) → FC7 (4096) → FC8 (1000). Use ReLU activations, dropout (p=0.5) on FC6/FC7, and overlapping pooling (stride 2). Train on ImageNet with SGD, initial lr=0.01, momentum 0.9, weight decay 5e-4, step lr decay, and heavy data augmentation (random crops, flips, color jitter). Parallelize across two GPUs by splitting filters/channel groups. Evaluate with top-1/top-5 accuracy; visualize learned kernels to ensure diverse edge/color detectors.\",\"repo\":\"https://github.com/akrizhevsky/cuda-convnet2\"},{\"id\":\"Dropout\",\"period\":\"2012\",\"title\":\"Dropout\",\"org\":\"University of Toronto\",\"location\":\"https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf\",\"paperTitle\":\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\",\"authors\":[\"Nitish Srivastava\",\"Geoffrey Hinton\",\"Alex Krizhevsky\",\"Ilya Sutskever\",\"Ruslan Salakhutdinov\"],\"description\":\"Dropout introduced a powerful regularization technique by randomly dropping units during training, preventing co-adaptation of features. This simple method significantly reduced overfitting in deep neural networks by training an ensemble of exponentially many sub-networks. Dropout became a standard regularization technique and enabled the training of larger networks without excessive overfitting.\",\"icon\":\"ml/toronto.svg\",\"details\":\"Implement dropout by zeroing activations with probability p during training: given activation vector a, sample binary mask m ∼ Bernoulli(1−p) and compute ã = (m ⊙ a)/(1−p) to keep expected magnitude constant (inverted dropout). At inference, skip masking. Apply dropout after fully connected or convolutional layers (with channel-wise masks for convs to preserve spatial structure). Tune p based on layer depth (typical values: 0.1–0.3 for convs, 0.5 for fully connected). Monitor training vs validation curves; dropout should reduce the gap without harming convergence. Combine with weight decay and batch norm for best results.\"},{\"id\":\"Word2Vec\",\"period\":\"2013\",\"title\":\"Word2Vec\",\"org\":\"Google\",\"location\":\"https://arxiv.org/pdf/1301.3781.pdf\",\"paperTitle\":\"Efficient Estimation of Word Representations in Vector Space\",\"authors\":[\"Tomas Mikolov\",\"Kai Chen\",\"Greg Corrado\",\"Jeffrey Dean\"],\"description\":\"Word2Vec introduced efficient methods (Skip-gram and CBOW) for learning dense vector representations of words from large corpora. These embeddings captured semantic and syntactic relationships, enabling vector arithmetic like 'king' - 'man' + 'woman' ≈ 'queen'. Word2Vec revolutionized natural language processing by providing a scalable way to represent words as continuous vectors, becoming foundational for modern NLP.\",\"icon\":\"ml/google.png\",\"details\":\"To train Skip-gram with negative sampling (SGNS): iterate over tokenized text, for each center word w_c predict surrounding context words w_o within a window k. For each positive pair (w_c, w_o), sample K negatives from the unigram distribution^0.75. Optimize log σ(u_o·v_c) + Σ log σ(−u_n·v_c), where v are input embeddings and u are output embeddings. Use subsampling to drop frequent words via P_drop(w)=1−√(t/f(w)). Implement with efficient batching (e.g., PyTorch’s EmbeddingBag) and asynchronous updates (Hogwild) for speed. After training, discard output vectors and use v as word embeddings. Evaluate via analogy tasks or downstream classifiers.\",\"repo\":\"https://github.com/google/word2vec\"},{\"id\":\"VAE\",\"period\":\"2013\",\"title\":\"Variational Autoencoder (VAE)\",\"org\":\"University of Amsterdam\",\"location\":\"https://arxiv.org/pdf/1312.6114.pdf\",\"paperTitle\":\"Auto-Encoding Variational Bayes\",\"authors\":[\"Diederik P. Kingma\",\"Max Welling\"],\"description\":\"VAE introduced a probabilistic approach to learning latent representations by combining variational inference with neural networks. It learns a distribution over latent codes rather than deterministic encodings, enabling both efficient inference and generation. VAE provided a principled framework for generative modeling and became influential in unsupervised learning, representation learning, and generative AI.\",\"icon\":\"ml/amsterdam.svg\",\"details\":\"Implement a VAE with encoder qϕ(z|x) producing mean μ and log-variance log σ², and decoder pθ(x|z) producing reconstruction parameters. During training, sample z via reparameterization: z = μ + σ ⊙ ε, ε ∼ N(0,I), to keep gradients flowing. Optimize the ELBO: L = E_q[log pθ(x|z)] − KL[qϕ(z|x) || N(0,I)], using Monte Carlo estimates and backprop. Choose Gaussian likelihood for continuous data or Bernoulli for binary images (MNIST). Regularize by β-annealing or KL warm-up to prevent posterior collapse. Evaluate with reconstruction error and latent-space traversals; sample new data by drawing z ∼ N(0,I) and decoding.\"},{\"id\":\"GAN\",\"period\":\"2014\",\"title\":\"Generative Adversarial Network (GAN)\",\"org\":\"Université de Montréal\",\"location\":\"https://arxiv.org/pdf/1406.2661.pdf\",\"paperTitle\":\"Generative Adversarial Networks\",\"authors\":[\"Ian J. Goodfellow\",\"Jean Pouget-Abadie\",\"Mehdi Mirza\",\"Bing Xu\",\"David Warde-Farley\",\"Sherjil Ozair\",\"Aaron Courville\",\"Yoshua Bengio\"],\"description\":\"GAN introduced a game-theoretic framework where a generator network learns to create realistic data by competing against a discriminator network. This adversarial training process enabled the generation of highly realistic images without requiring explicit modeling of probability distributions. GANs revolutionized generative modeling and spawned numerous applications in image synthesis, style transfer, and data augmentation.\",\"icon\":\"ml/montreal.png\",\"details\":\"To train a vanilla GAN: define generator G(z;θ_g) that maps latent noise z ∼ N(0,I) to data space, and discriminator D(x;θ_d) that outputs probability of x being real. Alternate optimization steps: (1) update D by maximizing log D(x_real) + log(1 − D(G(z))); (2) update G by maximizing log D(G(z)) (or minimizing log(1−D(G(z)))). Use Adam (lr=2e−4, β1=0.5) and batch normalization in G/D to stabilize. Monitor losses and generated samples to avoid mode collapse; techniques like label smoothing, gradient penalty, or WGAN objectives improve stability. Post-training, generate data by sampling fresh z and passing through G.\"},{\"id\":\"Adam\",\"period\":\"2014\",\"title\":\"Adam Optimizer\",\"org\":\"OpenAI, University of Toronto\",\"location\":\"https://arxiv.org/pdf/1412.6980.pdf\",\"paperTitle\":\"Adam: A Method for Stochastic Optimization\",\"authors\":[\"Diederik P. Kingma\",\"Jimmy Ba\"],\"description\":\"Adam combined the benefits of AdaGrad and RMSProp by computing adaptive learning rates for each parameter using estimates of first and second moments of gradients. It included bias correction terms and proved robust across a wide range of problems with minimal hyperparameter tuning. Adam became the most widely used optimizer in deep learning due to its efficiency, ease of use, and strong empirical performance.\",\"icon\":\"ml/openai.svg\",\"details\":\"Implement Adam updates as follows for parameter θ: maintain m_t (first moment) and v_t (second moment). Given gradient g_t, update m_t = β1 m_{t−1} + (1−β1) g_t, v_t = β2 v_{t−1} + (1−β2) g_t^2. Bias-correct: m̂_t = m_t / (1−β1^t), v̂_t = v_t / (1−β2^t). Apply parameter update θ ← θ − α · m̂_t / (√(v̂_t) + ε), with defaults α=1e−3, β1=0.9, β2=0.999, ε=1e−8. Implement weight decay separately (AdamW) to avoid coupling decay with adaptive steps. Monitor training by checking for divergence when β1 or β2 are set too high, and consider decoupled learning-rate schedulers or warm restarts for large-scale training.\"},{\"id\":\"Seq2Seq\",\"period\":\"2014\",\"title\":\"Sequence-to-Sequence Learning\",\"org\":\"Google\",\"location\":\"https://arxiv.org/pdf/1409.3215.pdf\",\"paperTitle\":\"Sequence to Sequence Learning with Neural Networks\",\"authors\":[\"Ilya Sutskever\",\"Oriol Vinyals\",\"Quoc V. Le\"],\"description\":\"Seq2Seq introduced an end-to-end framework for sequence transduction using an encoder-decoder architecture with LSTMs. The encoder maps variable-length input sequences to fixed-size representations, which the decoder transforms into variable-length output sequences. This architecture unified many NLP tasks under a single framework and achieved breakthrough results in machine translation, establishing neural approaches as state-of-the-art.\",\"icon\":\"ml/google.png\",\"details\":\"Build a Seq2Seq translator with LSTM encoder-decoder: embed input tokens, pass through a bidirectional LSTM to produce hidden states. Use the final encoder state to initialize the decoder LSTM. During training, apply teacher forcing: feed ground-truth previous token to the decoder, project hidden state to vocabulary logits, and minimize cross-entropy. At inference, decode autoregressively with greedy or beam search. Handle variable lengths via padding + masking, and add attention (Bahdanau/Luong) to improve long-sentence performance. Optimizers like Adam with scheduled learning rates and label smoothing help stabilize training on large corpora.\",\"repo\":\"https://github.com/google/seq2seq\"},{\"id\":\"Bahdanau_Attention\",\"period\":\"2014\",\"title\":\"Attention Mechanism\",\"org\":\"Université de Montréal\",\"location\":\"https://arxiv.org/pdf/1409.0473.pdf\",\"paperTitle\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"authors\":[\"Dzmitry Bahdanau\",\"Kyunghyun Cho\",\"Yoshua Bengio\"],\"description\":\"Bahdanau attention addressed the bottleneck in sequence-to-sequence models by allowing the decoder to focus on different parts of the input sequence at each decoding step. This attention mechanism computed context vectors as weighted sums of encoder hidden states, where weights were learned based on relevance. Attention became a fundamental building block of modern NLP systems and directly inspired the transformer architecture.\",\"icon\":\"ml/montreal.png\",\"details\":\"To add additive (Bahdanau) attention, compute alignment scores e_t,i = vᵗ tanh(W₁h_{t−1} + W₂hᵢ) between decoder hidden state h_{t−1} and each encoder hidden state hᵢ. Normalize via softmax α_t,i = softmax(e_t,i), then form context vector c_t = Σ α_t,i hᵢ. Concatenate c_t with decoder input (or hidden state) before predicting the next token. Implement efficiently by stacking encoder states and using batched matrix ops. Train end-to-end with Seq2Seq loss; inspect heatmaps of α to ensure the decoder attends to relevant source positions. This mechanism alleviates the fixed-length bottleneck and improves translations of long sentences.\"},{\"id\":\"GloVe\",\"period\":\"2014\",\"title\":\"GloVe Word Embeddings\",\"org\":\"Stanford University\",\"location\":\"https://nlp.stanford.edu/pubs/glove.pdf\",\"paperTitle\":\"GloVe: Global Vectors for Word Representation\",\"authors\":[\"Jeffrey Pennington\",\"Richard Socher\",\"Christopher D. Manning\"],\"description\":\"GloVe combined global matrix factorization with local context window methods for learning word embeddings. It trained on aggregated word-word co-occurrence statistics to produce vectors with meaningful linear substructures. GloVe provided an alternative to Word2Vec with strong performance on word analogy and similarity tasks, and its pre-trained vectors became widely used in NLP applications.\",\"icon\":\"ml/stanford.png\",\"details\":\"Implement GloVe by constructing a sparse co-occurrence matrix X where X_ij counts how often word j appears in the context of word i within a window. Optimize the weighted least-squares objective: Σ f(X_ij) (w_iᵗ w̃_j + b_i + b̃_j − log X_ij)^2, where f(x) = min((x/x_max)^α, 1). Typical hyperparameters: x_max = 100, α = 0.75, embedding dimension 100–300. Use AdaGrad or Adam with mini-batches over non-zero entries. After training, sum word and context vectors (w_i + w̃_i) to form the final embedding. Evaluate on word analogy tasks by checking that vector differences correspond to semantic relations.\",\"repo\":\"https://github.com/stanfordnlp/GloVe\"},{\"id\":\"Neural_Turing_Machine\",\"period\":\"2014\",\"title\":\"Neural Turing Machine\",\"org\":\"Google DeepMind\",\"location\":\"https://arxiv.org/pdf/1410.5401.pdf\",\"paperTitle\":\"Neural Turing Machines\",\"authors\":[\"Alex Graves\",\"Greg Wayne\",\"Ivo Danihelka\"],\"description\":\"Neural Turing Machines extended neural networks by coupling them to external memory resources accessed through attention mechanisms. The entire system was differentiable end-to-end, allowing gradient-based training. NTMs demonstrated that neural networks could learn simple algorithms like copying, sorting, and associative recall from examples alone, showing that neural networks could exhibit more algorithmic and programmable behavior.\",\"icon\":\"ml/deepmind.svg\",\"details\":\"To experiment with NTMs, implement a controller (LSTM) connected to an external memory matrix M. Read heads produce attention weights over memory via content-based addressing (similarity between key vector and memory rows) optionally shifted by learned convolutional kernels for location-based addressing. The read vector r is a weighted sum of memory rows. Write heads emit erase and add vectors to modify memory: M ← M ⊙ (1 − w ⊗ e) + w ⊗ a. At each timestep, concatenate controller output with read vectors to produce task outputs. Train via gradient descent on algorithmic tasks (copy, repeat-copy). Monitor attention distributions to ensure the model learns consistent read/write patterns.\"},{\"id\":\"BatchNorm\",\"period\":\"2015\",\"title\":\"Batch Normalization\",\"org\":\"Google\",\"location\":\"https://arxiv.org/pdf/1502.03167.pdf\",\"paperTitle\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"authors\":[\"Sergey Ioffe\",\"Christian Szegedy\"],\"description\":\"Batch Normalization normalized layer inputs across mini-batches, stabilizing training by reducing internal covariate shift. It enabled much higher learning rates, reduced sensitivity to initialization, and acted as a regularizer. Batch normalization dramatically accelerated training and became a standard component in deep networks, enabling the training of very deep architectures that were previously difficult to optimize.\",\"icon\":\"ml/google.png\",\"details\":\"For each batch, compute mean μ_B and variance σ²_B of activations for a given feature. Normalize: ˜ x = (x − μ_B) / √(σ²_B + ε), then scale and shift with learnable γ, β: y = γ ˜ x + β. Insert BN between linear/conv layers and nonlinearities (typically before ReLU). During inference, use running averages of μ_B and σ²_B accumulated during training. BN allows higher learning rates and reduces dependency on initialization. When batch sizes are small, switch to LayerNorm or GroupNorm. Remember to disable dropout before BN in the layer order (Conv → BN → ReLU).\"},{\"id\":\"ResNet\",\"period\":\"2015\",\"title\":\"Residual Networks (ResNet)\",\"org\":\"Microsoft Research\",\"location\":\"https://arxiv.org/pdf/1512.03385.pdf\",\"paperTitle\":\"Deep Residual Learning for Image Recognition\",\"authors\":[\"Kaiming He\",\"Xiangyu Zhang\",\"Shaoqing Ren\",\"Jian Sun\"],\"description\":\"ResNet introduced skip connections that allowed gradients to flow directly through networks by learning residual mappings. This simple architectural change enabled the training of networks with hundreds or even thousands of layers without degradation problems. ResNet won ImageNet 2015 and demonstrated that very deep networks could be effectively trained, fundamentally changing how we design neural network architectures.\",\"icon\":\"ml/microsoft.png\",\"details\":\"Implement ResNet-50 using bottleneck blocks: 1×1 conv (reduce channels) → 3×3 conv → 1×1 conv (expand), each followed by BatchNorm + ReLU. Add identity shortcuts so block output is F(x)+x; when spatial or channel dimensions change, apply a 1×1 projection to the shortcut. Arrange blocks in stages {3,4,6,3} with stride-2 downsampling at stage boundaries. Train on ImageNet with SGD (lr=0.1, momentum 0.9, weight decay 1e−4) and step/cosine LR schedules, using data augmentation (random crops, flips, color jitter). Residual connections preserve gradient flow, enabling very deep stacks—monitor training to ensure earlier layers remain active and validation accuracy surpasses non-residual baselines.\",\"repo\":\"https://github.com/KaimingHe/deep-residual-networks\"},{\"id\":\"Layer_Normalization\",\"period\":\"2016\",\"title\":\"Layer Normalization\",\"org\":\"University of Toronto\",\"location\":\"https://arxiv.org/pdf/1607.06450.pdf\",\"paperTitle\":\"Layer Normalization\",\"authors\":[\"Jimmy Lei Ba\",\"Jamie Ryan Kiros\",\"Geoffrey E. Hinton\"],\"description\":\"Layer Normalization normalized inputs across features for each example independently, unlike batch normalization which normalized across the batch dimension. This made it particularly effective for recurrent neural networks and sequences of varying length. Layer normalization stabilized hidden state dynamics in RNNs and later became the standard normalization technique in transformer architectures.\",\"icon\":\"ml/toronto.svg\",\"details\":\"For a hidden vector h with H features, compute μ = (1/H) Σ h_i and σ² = (1/H) Σ (h_i − μ)^2 per sample. Normalize as ˜ h = (h − μ) / √(σ² + ε), then learn affine parameters γ, β so output y = γ ⊙ ˜ h + β. Apply LayerNorm to each timestep independently in RNNs or to the last dimension in transformers (often before attention/MLP sublayers in a pre-LN architecture). Since statistics are sample-wise, LN works with batch size 1 and avoids running averages. Implementation in PyTorch: nn.LayerNorm(hidden_dim). Tune ε to avoid numerical issues when σ is small.\"},{\"id\":\"BPE\",\"period\":\"2016\",\"title\":\"Subword Units (BPE): Solving the Rare Word Problem\",\"org\":\"University of Edinburgh\",\"location\":\"https://arxiv.org/pdf/1508.07909.pdf\",\"paperTitle\":\"Neural Machine Translation of Rare Words with Subword Units\",\"authors\":[\"Rico Sennrich\",\"Barry Haddow\",\"Alexandra Birch\"],\"description\":\"Byte-Pair Encoding (BPE) adapted a data compression algorithm for neural machine translation, enabling open-vocabulary learning by breaking words into subword units. This solved the rare word problem by representing infrequent words as sequences of common subwords. BPE became the standard tokenization approach for language models, enabling models to handle any word while maintaining reasonable vocabulary sizes, and is used in GPT, BERT, and most modern LLMs.\",\"icon\":\"ml/edinburgh.png\",\"details\":\"To train BPE, initialize the vocabulary with all characters (or bytes) and count symbol pair frequencies in the corpus. Iteratively merge the most frequent adjacent pair (e.g., 't'+'h'→'th'), add the new token to the vocabulary, and update the corpus by replacing occurrences of that pair. Repeat until reaching the desired vocab size (typically 30k–50k). At tokenization time, greedily apply the learned merges from most to least frequent to segment new words into subwords. For neural models, replace words with their subword sequences before feeding them into embeddings. Libraries like SentencePiece or Hugging Face tokenizers expose BPE training/payment APIs; ensure consistent pre-processing (lowercasing, normalization) between training and inference.\",\"repo\":\"https://github.com/rsennrich/subword-nmt\"},{\"id\":\"Transformer\",\"period\":\"2017\",\"title\":\"Transformer Architecture\",\"org\":\"Google\",\"location\":\"https://arxiv.org/pdf/1706.03762.pdf\",\"paperTitle\":\"Attention Is All You Need\",\"authors\":[\"Ashish Vaswani\",\"Noam Shazeer\",\"Niki Parmar\",\"Jakob Uszkoreit\",\"Llion Jones\",\"Aidan N. Gomez\",\"Łukasz Kaiser\",\"Illia Polosukhin\"],\"description\":\"The Transformer replaced recurrence and convolutions entirely with self-attention mechanisms, processing sequences in parallel rather than sequentially. It introduced multi-head attention, positional encodings, and a feedforward encoder-decoder structure. The Transformer achieved state-of-the-art translation results while being more parallelizable and requiring significantly less training time. This architecture became the foundation for modern large language models and revolutionized NLP.\",\"icon\":\"ml/google.png\",\"details\":\"Implement a Transformer block with multi-head attention and position-wise feedforward layers. For attention, project inputs to Q, K, V, split into h heads, compute softmax(QKᵗ/√d_k)V with masking for padding/causal constraints, then concatenate heads and project back. Add residual connections and LayerNorm around attention and feedforward sublayers (pre-LN: LN → sublayer → residual). Encode sequence order with sinusoidal or learned positional embeddings. Stack encoder blocks; decoder blocks include masked self-attention plus encoder–decoder attention. Train with Adam (β₁=0.9, β₂=0.98) and warmup/inverse-sqrt LR schedule, apply label smoothing and dropout. Use beam search during inference.\",\"repo\":\"https://github.com/tensorflow/tensor2tensor\"},{\"id\":\"RLHF\",\"period\":\"2017\",\"title\":\"Reinforcement Learning from Human Feedback (RLHF)\",\"org\":\"OpenAI, UC Berkeley, DeepMind\",\"location\":\"https://arxiv.org/pdf/1706.03741.pdf\",\"paperTitle\":\"Deep Reinforcement Learning from Human Preferences\",\"authors\":[\"Paul Christiano\",\"Jan Leike\",\"Tom Brown\",\"Miljan Martic\",\"Shane Legg\",\"Dario Amodei\"],\"description\":\"RLHF introduced a method for training RL agents using human preference comparisons rather than hand-crafted reward functions. Humans compared pairs of trajectory segments, and a reward model was trained to predict preferences. This reward model then guided policy optimization. RLHF scaled preference-based learning to complex tasks and later became crucial for aligning large language models with human values and intentions.\",\"icon\":\"ml/openai.svg\",\"details\":\"RLHF pipeline: (1) Collect human preference pairs between model outputs or trajectories. (2) Train a reward model Rϕ(x,y) using logistic regression on preference data: maximize log σ(Rϕ(y_a) − Rϕ(y_b)). (3) Fine-tune the base policy π using RL (often PPO) with reward Rϕ minus a KL penalty toward a reference policy to prevent drift. Implement PPO with clipped objective, advantages from GAE, and KL coefficient tuned to maintain target divergence. Evaluate alignment via held-out preference evaluations and safety audits.\"},{\"id\":\"MoE\",\"period\":\"2017\",\"title\":\"Sparsely-Gated Mixture of Experts\",\"org\":\"Google\",\"location\":\"https://arxiv.org/pdf/1701.06538.pdf\",\"paperTitle\":\"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\",\"authors\":[\"Noam Shazeer\",\"Azalia Mirhoseini\",\"Krzysztof Maziarz\",\"Andy Davis\",\"Quoc Le\",\"Geoffrey Hinton\",\"Jeff Dean\"],\"description\":\"Mixture of Experts introduced conditional computation where a gating network routes each input to a sparse subset of expert sub-networks. This enabled training models with orders of magnitude more parameters without proportional increases in computation. MoE demonstrated that model capacity could be dramatically increased through sparsity, achieving state-of-the-art results in language modeling and translation. This approach later influenced large-scale models like GPT-4.\",\"icon\":\"ml/google.png\",\"details\":\"Build a sparsely gated MoE layer by defining E experts (feedforward networks) and a gating network producing logits g. Select top-k experts per token (k=1 or 2) using softmax probabilities and optionally add noise for exploration. Route inputs to chosen experts, weight their outputs by gate probabilities, and sum. Include load-balancing losses to keep expert utilization even. Implement with efficient dispatch/combination ops (e.g., Switch Transformer routing). Train end-to-end with standard optimizers, monitor expert load metrics, and adjust k or noise to avoid expert collapse.\"},{\"id\":\"PPO\",\"period\":\"2017\",\"title\":\"Proximal Policy Optimization (PPO)\",\"org\":\"OpenAI\",\"location\":\"https://arxiv.org/pdf/1707.06347.pdf\",\"paperTitle\":\"Proximal Policy Optimization Algorithms\",\"authors\":[\"John Schulman\",\"Filip Wolski\",\"Prafulla Dhariwal\",\"Alec Radford\",\"Oleg Klimov\"],\"description\":\"PPO introduced a simpler and more stable policy gradient method by clipping the objective function to prevent excessively large policy updates. It combined the benefits of trust region methods with the simplicity of first-order optimization. PPO became the most widely used reinforcement learning algorithm due to its robustness, ease of implementation, and strong empirical performance across diverse tasks.\",\"icon\":\"ml/openai.svg\",\"details\":\"Implement PPO with clipped surrogate objective: L = E[min(r_t(θ)Â_t, clip(r_t(θ), 1−ε, 1+ε)Â_t)], where r_t is the probability ratio and Â_t Generalized Advantage Estimation. Collect trajectories with π_old, compute returns/advantages, then run multiple epochs of mini-batch SGD (Adam lr≈3e−4) updating both policy and value heads. Include value loss and entropy bonus; monitor KL divergence to adjust learning rate or early-stop. Works for continuous control (Gaussian policies with tanh outputs) and discrete actions. Use normalized advantages and gradient clipping for stability.\",\"repo\":\"https://github.com/openai/baselines\"},{\"id\":\"ELMo\",\"period\":\"2018\",\"title\":\"ELMo (Embeddings from Language Models)\",\"org\":\"Allen Institute for AI, University of Washington\",\"location\":\"https://arxiv.org/pdf/1802.05365.pdf\",\"paperTitle\":\"Deep Contextualized Word Representations\",\"authors\":[\"Matthew E. Peters\",\"Mark Neumann\",\"Mohit Iyyer\",\"Matt Gardner\",\"Christopher Clark\",\"Kenton Lee\",\"Luke Zettlemoyer\"],\"description\":\"ELMo generated context-dependent word representations by using bidirectional LSTMs trained as language models. Unlike static embeddings, ELMo representations varied based on context, capturing polysemy and complex linguistic features. ELMo demonstrated the power of pre-training and fine-tuning, significantly improving performance across diverse NLP tasks. It was a crucial step toward modern contextualized language models and transfer learning in NLP.\",\"icon\":\"ml/allen_ai.svg\",\"details\":\"Train a bidirectional 2-layer LSTM language model on large text (e.g., 1B Word Benchmark). For each token, concatenate forward and backward hidden states from all layers, then learn task-specific scalar weights to combine them. During downstream training, keep LM weights fixed or fine-tune lightly while adding the weighted ELMo embeddings to the model input (or intermediate layers). Implementation tips: apply character CNNs to build robust token embeddings, use dropout/variational dropout in LSTMs, and train with sampled softmax for efficiency. Evaluate by plugging ELMo into tagging, QA, or classification models and measuring gains.\",\"repo\":\"https://github.com/allenai/bilm-tf\"},{\"id\":\"GPT\",\"period\":\"2018\",\"title\":\"GPT (Generative Pre-Training)\",\"org\":\"OpenAI\",\"location\":\"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf\",\"paperTitle\":\"Improving Language Understanding by Generative Pre-Training\",\"authors\":[\"Alec Radford\",\"Karthik Narasimhan\",\"Tim Salimans\",\"Ilya Sutskever\"],\"description\":\"GPT introduced a two-stage approach: unsupervised pre-training of a transformer language model on large text corpora, followed by supervised fine-tuning on specific tasks. This demonstrated that language models could learn general representations useful across many tasks. GPT showed that pre-training could significantly reduce the labeled data required for downstream tasks, establishing the pre-train-then-fine-tune paradigm that dominated subsequent NLP research.\",\"icon\":\"ml/openai.svg\",\"details\":\"To replicate GPT, train a decoder-only Transformer with masked self-attention on large text (e.g., BookCorpus). Use byte pair encoding, 12 layers, hidden size 768, 12 heads, context length 512, GELU activations, and learned positional embeddings. Optimize with Adam (β1=0.9, β2=0.95), LR warmup + cosine decay, and layer-wise LR decay. Fine-tune on downstream tasks by prepending task-specific prompts and continuing supervised training with small LR. Evaluation uses perplexity for pretraining and task-specific metrics (accuracy, F1) during fine-tuning.\",\"repo\":\"https://github.com/openai/finetune-transformer-lm\"},{\"id\":\"BERT\",\"period\":\"2018\",\"title\":\"BERT (Bidirectional Encoder Representations from Transformers)\",\"org\":\"Google\",\"location\":\"https://arxiv.org/pdf/1810.04805.pdf\",\"paperTitle\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"authors\":[\"Jacob Devlin\",\"Ming-Wei Chang\",\"Kenton Lee\",\"Kristina Toutanova\"],\"description\":\"BERT pre-trained bidirectional transformers using masked language modeling and next sentence prediction. Unlike previous unidirectional models, BERT jointly conditioned on both left and right context in all layers. BERT achieved state-of-the-art results across eleven NLP tasks and demonstrated that deeply bidirectional pre-training was crucial for language understanding. BERT became the foundation for numerous downstream applications and variants.\",\"icon\":\"ml/google.png\",\"details\":\"Pretrain BERT by randomly masking 15% of tokens (80% [MASK], 10% random token, 10% unchanged) and predicting them with a Transformer encoder (L=12 or 24). Add Next Sentence Prediction by classifying whether sentence B follows sentence A using [CLS] token representation. Use WordPiece tokenization, segment + position embeddings, GELU activations, dropout 0.1, Adam optimizer (lr=1e−4) with warmup over 10k steps and linear decay. Fine-tune by adding task-specific heads on [CLS] (classification) or token embeddings (QA, tagging) and training for a few epochs with small LR.\",\"repo\":\"https://github.com/google-research/bert\"},{\"id\":\"Mixed_Precision_Training\",\"period\":\"2018\",\"title\":\"Mixed Precision Training\",\"org\":\"NVIDIA\",\"location\":\"https://arxiv.org/pdf/1710.03740.pdf\",\"paperTitle\":\"Mixed Precision Training\",\"authors\":[\"Paulius Micikevicius\",\"Sharan Narang\",\"Jonah Alben\",\"Gregory Diamos\",\"Erich Elsen\",\"David Garcia\",\"Boris Ginsburg\",\"Michael Houston\",\"Olaf Klauser\",\"Andrew Kraljevic\",\"Chris Paine\",\"Naveen Satish\",\"Michael Wu\"],\"description\":\"Micikevicius et al. showed how to safely train deep networks using half-precision (FP16) arithmetic while preserving full-precision accuracy. By keeping FP32 master weights, accumulating gradients in FP32, and using loss scaling to avoid underflow, they demonstrated 2–3× speedups on NVIDIA Tensor Cores without sacrificing convergence. Mixed precision became the standard recipe for large-scale transformer training, enabling today’s models to fit within GPU memory budgets.\",\"icon\":\"ml/nvidia.png\",\"details\":\"To implement mixed precision, cast activations, gradients, and matrix multiplications to FP16/BF16 while maintaining FP32 master weights. Use dynamic loss scaling: multiply the loss by a scale factor S, backpropagate in FP16, check for overflow (NaNs/infs), and if none occur divide gradients by S before the optimizer step; otherwise skip the update and reduce S. Retain FP32 copies of weights and optimizer states (e.g., Adam’s moments) and update them in full precision, then cast the updated weights back to FP16 for the forward pass. Combine with Tensor Core-optimized kernels, gradient accumulation, and ZeRO-style sharding for maximal throughput. Frameworks such as NVIDIA Apex AMP and PyTorch’s torch.cuda.amp automate these steps—enable autocast for forward passes and wrap the backward step with GradScaler to manage loss scaling.\",\"repo\":\"https://github.com/NVIDIA/apex\"},{\"id\":\"GPT-2\",\"period\":\"2019\",\"title\":\"GPT-2\",\"org\":\"OpenAI\",\"location\":\"https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf\",\"paperTitle\":\"Language Models are Unsupervised Multitask Learners\",\"authors\":[\"Alec Radford\",\"Jeffrey Wu\",\"Rewon Child\",\"David Luan\",\"Dario Amodei\",\"Ilya Sutskever\"],\"description\":\"GPT-2 scaled up the original GPT to 1.5 billion parameters and trained on a larger, more diverse dataset. It demonstrated that language models could perform many tasks zero-shot without fine-tuning by simply conditioning on appropriate prompts. GPT-2 showed strong performance on diverse tasks including translation, summarization, and question answering, suggesting that with sufficient scale and data, language models naturally learn multitask capabilities.\",\"icon\":\"ml/openai.svg\",\"details\":\"GPT-2 extends GPT with larger decoder-only Transformers (117M–1.5B parameters) trained on WebText (45M web pages). Use byte-level BPE, context length 1024, GELU, residual/LN structure, and Adam with LR warmup + cosine decay. During inference, perform nucleus (top-p) or top-k sampling with temperature scaling to control creativity; apply repetition penalties to avoid loops. Evaluate zero-shot by crafting prompts for downstream tasks. Fine-tuning can be done via supervised objectives, but GPT-2 highlighted the power of zero-shot prompting on diverse benchmarks.\",\"repo\":\"https://github.com/openai/gpt-2\"},{\"id\":\"T5\",\"period\":\"2019\",\"title\":\"T5 (Text-to-Text Transfer Transformer)\",\"org\":\"Google\",\"location\":\"https://arxiv.org/pdf/1910.10683.pdf\",\"paperTitle\":\"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\",\"authors\":[\"Colin Raffel\",\"Noam Shazeer\",\"Adam Roberts\",\"Katherine Lee\",\"Sharan Narang\",\"Michael Matena\",\"Yanqi Zhou\",\"Wei Li\",\"Peter J. Liu\"],\"description\":\"T5 unified all NLP tasks into a text-to-text format where both inputs and outputs are text strings. It systematically explored transfer learning techniques including pre-training objectives, architectures, datasets, and fine-tuning methods. T5's encoder-decoder architecture and comprehensive evaluation provided insights into what makes transfer learning effective. The unified framework simplified multi-task learning and became influential for instruction-following models.\",\"icon\":\"ml/google.png\",\"details\":\"Convert every supervised task into a text prompt (e.g., “translate English to German: ...”) and train a Transformer encoder-decoder with relative position embeddings using span-corruption: mask contiguous spans and have the decoder reconstruct them. Use Adafactor optimizer, learning-rate warmup then inverse-square decay, dropout 0.1, and gradient checkpointing for large models. Fine-tune by continuing text-to-text training on task data, optionally with adapters or LoRA for efficiency. Evaluate outputs with beam search and task-specific metrics.\",\"repo\":\"https://github.com/google-research/text-to-text-transfer-transformer\"},{\"id\":\"Bitter_Lesson\",\"period\":\"2019\",\"title\":\"The Bitter Lesson\",\"org\":\"University of Alberta, DeepMind\",\"location\":\"http://www.incompleteideas.net/IncIdeas/BitterLesson.html\",\"paperTitle\":\"The Bitter Lesson (Essay)\",\"authors\":[\"Richard Sutton\"],\"description\":\"The Bitter Lesson essay argued that general methods leveraging computation consistently outperform approaches that rely on human knowledge in the long run. Sutton observed that search and learning, when given sufficient computation, surpass hand-crafted features and domain expertise. This philosophical perspective influenced the field to focus on scalable learning methods rather than encoding human knowledge, providing intellectual foundation for the scaling paradigm in modern AI.\",\"icon\":\"ml/alberta.png\",\"details\":\"Although conceptual, the Bitter Lesson guides implementation strategy: prioritize scalable compute-driven methods over manual heuristics. When tackling a problem, evaluate whether additional data, larger models, or automated search can outperform hand-crafted rules. Build pipelines that make scaling easy (efficient data ingestion, distributed training). Benchmark heuristic approaches against learned ones to quantify improvements as compute grows, and favor architectures that naturally benefit from scale (self-play, gradient-based learning).\"},{\"id\":\"Scaling_Laws\",\"period\":\"2020\",\"title\":\"Scaling Laws for Neural Language Models\",\"org\":\"OpenAI\",\"location\":\"https://arxiv.org/pdf/2001.08361.pdf\",\"paperTitle\":\"Scaling Laws for Neural Language Models\",\"authors\":[\"Jared Kaplan\",\"Sam McCandlish\",\"Tom Henighan\",\"Tom B. Brown\",\"Benjamin Chess\",\"Rewon Child\",\"Scott Gray\",\"Alec Radford\",\"Jeffrey Wu\",\"Dario Amodei\"],\"description\":\"This work empirically demonstrated that language model performance scales as power-laws with model size, dataset size, and compute budget. The research showed predictable relationships between these factors and suggested optimal allocation strategies. These scaling laws provided quantitative guidance for training large models and predicted that simply scaling up models would continue to yield improvements, influencing subsequent investment in large-scale model development.\",\"icon\":\"ml/openai.svg\",\"details\":\"Apply scaling laws by running models across a grid of parameter counts, dataset sizes, and compute budgets, logging validation loss. Fit power-law curves (log-loss vs. log-parameters) to estimate exponents. Use the fitted curves to predict optimal allocation of compute between model size and data (e.g., N ∝ C^α). Update fits when architecture/data change. This methodology lets you budget future training runs and estimate diminishing returns before committing resources.\"},{\"id\":\"GPT-3\",\"period\":\"2020\",\"title\":\"GPT-3\",\"org\":\"OpenAI\",\"location\":\"https://arxiv.org/pdf/2005.14165.pdf\",\"paperTitle\":\"Language Models are Few-Shot Learners\",\"authors\":[\"Tom B. Brown\",\"Benjamin Mann\",\"Nick Ryder\",\"Melanie Subbiah\",\"Jared Kaplan\",\"Prafulla Dhariwal\",\"Arvind Neelakantan\",\"Pranav Shyam\",\"Girish Sastry\",\"Amanda Askell\",\"Sandhini Agarwal\",\"Ariel Herbert-Voss\",\"Gretchen Krueger\",\"Tom Henighan\",\"Rewon Child\",\"Aditya Ramesh\",\"Daniel M. Ziegler\",\"Jeffrey Wu\",\"Clemens Winter\",\"Christopher Hesse\",\"Mark Chen\",\"Eric Sigler\",\"Mateusz Litwin\",\"Scott Gray\",\"Benjamin Chess\",\"Jack Clark\",\"Christopher Berner\",\"Sam McCandlish\",\"Alec Radford\",\"Ilya Sutskever\",\"Dario Amodei\"],\"description\":\"GPT-3 scaled transformers to 175 billion parameters, demonstrating that language models could perform diverse tasks with few-shot, one-shot, or zero-shot learning from prompts alone. It showed impressive performance on translation, question-answering, arithmetic, and novel word usage without gradient updates. GPT-3 revealed that with sufficient scale, language models develop broad capabilities and sparked widespread interest in large language models and prompt engineering.\",\"icon\":\"ml/openai.svg\",\"details\":\"GPT-3 uses a 96-layer decoder-only Transformer (hidden size 12,288, 96 heads) trained on ~300B tokens. Implement via distributed training: tensor/pipeline parallelism, ZeRO sharding, mixed precision (BF16), and gradient checkpointing. Use Adam with lr warmup then cosine decay, weight decay 0.01, and batch sizes in the millions of tokens. For inference, craft prompts with few-shot demonstrations and decode using top-k/top-p sampling. Evaluate zero-shot/few-shot performance on diverse benchmarks (SuperGLUE, LAMBADA) and run safety/bias audits.\"},{\"id\":\"ZeRO\",\"period\":\"2020\",\"title\":\"ZeRO (Zero Redundancy Optimizer)\",\"org\":\"Microsoft\",\"location\":\"https://arxiv.org/pdf/1910.02054.pdf\",\"paperTitle\":\"ZeRO: Memory Optimizations Toward Training Trillion Parameter Models\",\"authors\":[\"Samyam Rajbhandari\",\"Jeff Rasley\",\"Olatunji Ruwase\",\"Yuxiong He\"],\"description\":\"ZeRO eliminated memory redundancies in data-parallel distributed training by partitioning optimizer states, gradients, and parameters across devices rather than replicating them. ZeRO enabled training models with trillions of parameters by dramatically reducing per-device memory requirements while maintaining computational efficiency. This optimization became crucial for training large language models and is implemented in DeepSpeed, enabling the scale of models like GPT-3 and beyond.\",\"icon\":\"ml/microsoft.png\",\"details\":\"Implement ZeRO in stages: Stage 1 shards optimizer states (momentum/variance) across ranks; Stage 2 additionally shards gradients; Stage 3 partitions parameters themselves. Use DeepSpeed or FairScale to manage communication (reduce-scatter/all-gather) during forward/backward passes. Enable offloading to CPU/NVMe for very large models, and combine with activation checkpointing + mixed precision. Monitor memory by inspecting per-rank statistics; ZeRO lets you scale model size roughly linearly with number of GPUs without replicating optimizer state on each device.\",\"repo\":\"https://github.com/microsoft/DeepSpeed\"},{\"id\":\"RoPE\",\"period\":\"2021\",\"title\":\"RoFormer: Rotary Position Embedding (RoPE)\",\"org\":\"Zhuiyi Technology\",\"location\":\"https://arxiv.org/pdf/2104.09864.pdf\",\"paperTitle\":\"RoFormer: Enhanced Transformer with Rotary Position Embedding\",\"authors\":[\"Jianlin Su\",\"Yu Lu\",\"Shengfeng Pan\",\"Ahmed Murtadha\",\"Bo Wen\",\"Yunfeng Liu\"],\"description\":\"Rotary Position Embedding (RoPE) encodes position information by rotating word embeddings based on their absolute positions, while naturally encoding relative position information through the rotation properties. RoPE provided better extrapolation to longer sequences than previous position encoding methods while being computationally efficient. It was adopted by influential models including PaLM, LLaMA, and many other modern LLMs, becoming a preferred position encoding technique.\",\"icon\":\"ml/zhuiyi.png\",\"details\":\"To add RoPE, pair embedding dimensions into complex numbers and rotate each pair by angle θ = pos · base^{-2i/d}, where i indexes the pair and base is typically 10,000. Implementation: for queries/keys in attention, reshape to (seq, heads, d/2, 2) and apply rotation matrix [[cosθ, −sinθ],[sinθ, cosθ]]. This injects relative positional info without extra parameters. For long-context extrapolation, scale θ via linear interpolation or NTK scaling. Libraries like xformers and transformers provide rotary_embedding APIs—enable by setting rotary_emb_fraction and applying to Q/K before dot products.\",\"repo\":\"https://github.com/ZhuiyiTechnology/roformer\"},{\"id\":\"LoRA\",\"period\":\"2021\",\"title\":\"LoRA: Low-Rank Adaptation of Large Language Models\",\"org\":\"Microsoft\",\"location\":\"https://arxiv.org/pdf/2106.09685.pdf\",\"paperTitle\":\"LoRA: Low-Rank Adaptation of Large Language Models\",\"authors\":[\"Edward J. Hu\",\"Yelong Shen\",\"Phillip Wallis\",\"Zeyuan Allen-Zhu\",\"Yuanzhi Li\",\"Shean Wang\",\"Lu Wang\",\"Weizhu Chen\"],\"description\":\"LoRA enabled efficient fine-tuning of large language models by training low-rank decomposition matrices that are added to frozen pre-trained weights. This reduced trainable parameters by 10,000x and memory requirements by 3x while maintaining or exceeding full fine-tuning performance. LoRA made it practical to customize large models for specific tasks with limited compute resources, democratizing access to fine-tuning and enabling rapid adaptation of foundation models.\",\"icon\":\"ml/microsoft.png\",\"details\":\"To apply LoRA on a weight matrix W ∈ ℝ^{d_out×d_in}, freeze W and learn low-rank adapters: replace Wx with Wx + BAx, where B ∈ ℝ^{d_out×r}, A ∈ ℝ^{r×d_in} with r ≪ d. Initialize A randomly and B to zeros so the adapter starts as no-op. Train only A, B (and biases/LayerNorms) using standard optimizer; memory usage shrinks by ~d·r instead of d·d. At inference, merge BA into W if desired or keep separate. Frameworks like PEFT/HF provide APIs to inject LoRA into attention/query/value or MLP projections with a few lines of code.\",\"repo\":\"https://github.com/microsoft/LoRA\"},{\"id\":\"InstructGPT\",\"period\":\"2022\",\"title\":\"InstructGPT\",\"org\":\"OpenAI\",\"location\":\"https://arxiv.org/pdf/2203.02155.pdf\",\"paperTitle\":\"Training Language Models to Follow Instructions with Human Feedback\",\"authors\":[\"Long Ouyang\",\"Jeff Wu\",\"Xu Jiang\",\"Diogo Almeida\",\"Carroll L. Wainwright\",\"Pamela Mishkin\",\"Chong Zhang\",\"Sandhini Agarwal\",\"Katarina Slama\",\"Alex Ray\",\"John Schulman\",\"Jacob Hilton\",\"Fraser Kelton\",\"Luke Miller\",\"Maddie Simens\",\"Amanda Askell\",\"Peter Welinder\",\"Paul Christiano\",\"Jan Leike\",\"Ryan Lowe\"],\"description\":\"InstructGPT fine-tuned GPT-3 using supervised learning on human-written demonstrations followed by reinforcement learning from human feedback. Despite having 100x fewer parameters, InstructGPT outputs were preferred to GPT-3 outputs. The model showed improvements in truthfulness, helpfulness, and reduced toxicity. InstructGPT demonstrated that alignment with human preferences through RLHF was crucial for making language models useful and safe, establishing the approach used in ChatGPT.\",\"icon\":\"ml/openai.svg\",\"details\":\"InstructGPT pipeline: (1) Collect instruction-following examples and do supervised fine-tuning on GPT-3 (π_SFT). (2) Gather human preference comparisons over model outputs and train a reward model. (3) Run PPO with reward model + KL penalty toward π_SFT to produce π_RLHF. Implementation tips: ensure diverse instructions, balance reward model capacity vs. overfitting, and monitor KL divergence to keep outputs fluent. Evaluate via human preference studies, toxicity/truthfulness benchmarks, and red-teaming.\"},{\"id\":\"Chain_of_Thought\",\"period\":\"2022\",\"title\":\"Chain-of-Thought Prompting\",\"org\":\"Google Research\",\"location\":\"https://arxiv.org/pdf/2201.11903.pdf\",\"paperTitle\":\"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\",\"authors\":[\"Jason Wei\",\"Xuezhi Wang\",\"Dale Schuurmans\",\"Maarten Bosma\",\"Brian Ichter\",\"Fei Xia\",\"Ed Chi\",\"Quoc Le\",\"Denny Zhou\"],\"description\":\"Chain-of-thought prompting enabled language models to solve complex reasoning tasks by generating intermediate reasoning steps before arriving at final answers. Simply adding a few examples with reasoning chains dramatically improved performance on arithmetic, commonsense, and symbolic reasoning tasks. This technique revealed emergent reasoning capabilities in large models and demonstrated that prompting strategies could unlock latent abilities without additional training.\",\"icon\":\"ml/google.png\",\"details\":\"To elicit chain-of-thought (CoT), craft few-shot prompts that include question, detailed reasoning steps, and final answer (e.g., “Q: ... A: Let’s think step by step. ... Therefore, answer is ...”). During inference, prepend this prompt and sample with temperature ~0.7 or nucleus sampling to encourage diverse reasoning. For deterministic outputs, run majority voting via self-consistency: sample multiple CoTs, then pick the most common final answer. Evaluate by comparing accuracy with/without CoT. For smaller models, distill CoT by training on generated rationales or use “scratchpad” tokens so the model learns to produce intermediate steps.\"},{\"id\":\"FlashAttention\",\"period\":\"2022\",\"title\":\"FlashAttention\",\"org\":\"Stanford University\",\"location\":\"https://arxiv.org/pdf/2205.14135.pdf\",\"paperTitle\":\"FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\",\"authors\":[\"Tri Dao\",\"Daniel Y. Fu\",\"Stefano Ermon\",\"Atri Rudra\",\"Christopher Ré\"],\"description\":\"FlashAttention optimized the attention mechanism by accounting for GPU memory hierarchy, using tiling to reduce data movement between GPU memory levels. This IO-aware algorithm achieved exact attention with significantly reduced memory usage and 2-4x speedup compared to standard implementations. FlashAttention enabled training transformers with much longer context lengths and became widely adopted, fundamentally improving the efficiency of transformer models.\",\"icon\":\"ml/stanford.png\",\"details\":\"FlashAttention computes attention via tiled blocks: split Q/K/V into tiles that fit in SRAM, compute softmax incrementally while maintaining running max/sum for numerical stability, and write outputs back to HBM only once. Use libraries (flash-attn, PyTorch 2’s SDPA) to enable by setting supported head dimensions (multiples of 8/16) and contiguous memory layouts. When implementing manually, fuse operations (QKᵗ, softmax, AV) into a single kernel to minimize memory traffic. Validate by comparing outputs to standard attention and measuring speedups for long sequences.\",\"repo\":\"https://github.com/Dao-AILab/flash-attention\"},{\"id\":\"Constitutional_AI\",\"period\":\"2022\",\"title\":\"Constitutional AI: Harmlessness from AI Feedback\",\"org\":\"Anthropic\",\"location\":\"https://arxiv.org/pdf/2212.08073.pdf\",\"paperTitle\":\"Constitutional AI: Harmlessness from AI Feedback\",\"authors\":[\"Yuntao Bai\",\"Saurav Kadavath\",\"Sandipan Kundu\",\"Amanda Askell\",\"Jackson Kernion\",\"Andy Jones\",\"Anna Chen\",\"Anna Goldie\",\"Azalia Mirhoseini\",\"Cameron McKinnon\",\"Carol Chen\",\"Catherine Olsson\",\"Christopher Olah\",\"Danny Hernandez\",\"Dawn Drain\",\"Deep Ganguli\",\"Dustin Li\",\"Eli Tran-Johnson\",\"Ethan Perez\",\"Jamie Kerr\",\"Jared Mueller\",\"Jeffrey Ladish\",\"Joshua Landau\",\"Kamal Ndousse\",\"Kamile Lukosuite\",\"Liane Lovitt\",\"Michael Sellitto\",\"Nelson Elhage\",\"Nicholas Schiefer\",\"Noemi Mercado\",\"Nova DasSarma\",\"Robert Lasenby\",\"Robin Larson\",\"Sam Ringer\",\"Scott Johnston\",\"Shauna Kravec\",\"Sheer El Showk\",\"Stanislav Fort\",\"Tamera Lanham\",\"Timothy Telleen-Lawton\",\"Tom Conerly\",\"Tom Henighan\",\"Tristan Hume\",\"Samuel R. Bowman\",\"Zac Hatfield-Dodds\",\"Ben Mann\",\"Dario Amodei\",\"Nicholas Joseph\",\"Sam McCandlish\",\"Tom Brown\",\"Jared Kaplan\"],\"description\":\"Constitutional AI introduced a method for training harmless AI assistants using AI-generated feedback based on a set of principles (a 'constitution') rather than relying solely on human feedback. The model critiques and revises its own responses according to constitutional principles, then learns from these self-improvements. This approach reduced reliance on human labelers for harmlessness training while making the values guiding AI behavior more transparent and debuggable.\",\"icon\":\"ml/anthropic.svg\",\"details\":\"To implement Constitutional AI, define a set of principles (e.g., “be helpful, avoid hate speech”). Generate model responses, then use the same model (or a critic model) to critique each response according to the constitution, producing revision instructions. Iterate: response → critique → revised response. Train a supervised model on (prompt, revised response) pairs. Optionally fine-tune with RL using AI-generated preference data anchored to the constitution. Monitor adherence by auditing responses against the principle set and adjusting the constitution/critique prompts as needed.\"},{\"id\":\"DPO\",\"period\":\"2023\",\"title\":\"Direct Preference Optimization (DPO)\",\"org\":\"Stanford University\",\"location\":\"https://arxiv.org/pdf/2305.18290.pdf\",\"paperTitle\":\"Direct Preference Optimization: Your Language Model is Secretly a Reward Model\",\"authors\":[\"Rafael Rafailov\",\"Archit Sharma\",\"Eric Mitchell\",\"Stefano Ermon\",\"Christopher D. Manning\",\"Chelsea Finn\"],\"description\":\"DPO simplified preference learning by directly optimizing language models on human preferences without requiring a separate reward model or reinforcement learning. It reformulated RLHF as a classification problem over preference pairs, making training more stable and efficient. DPO achieved comparable or better results than RLHF while being simpler to implement and tune, becoming a popular alternative for aligning language models with human preferences.\",\"icon\":\"ml/stanford.png\",\"details\":\"DPO objective: given preference pairs (y_w, y_l) for prompt x, maximize log σ(β(log πθ(y_w|x) − log πθ(y_l|x)) − Δ), where Δ is log ratio under reference policy π_ref. Implementation steps: compute log-probs for both samples, subtract reference log-probs, apply logistic loss. Use the same architecture as the base LM; no separate reward model or RL loop is needed. Train with standard optimizers on preference datasets, apply KL regularization via reference log-probs, and evaluate alignment by measuring preference accuracy and safety benchmarks. DPO is stochastic-gradient friendly and integrates easily with PEFT or LoRA adapters.\",\"repo\":\"https://github.com/eric-mitchell/direct-preference-optimization\"},{\"id\":\"QLoRA\",\"period\":\"2023\",\"title\":\"QLoRA: Efficient Fine-Tuning of Quantized LLMs\",\"org\":\"University of Washington\",\"location\":\"https://arxiv.org/pdf/2305.14314.pdf\",\"paperTitle\":\"QLoRA: Efficient Finetuning of Quantized LLMs\",\"authors\":[\"Tim Dettmers\",\"Artidoro Pagnoni\",\"Ari Holtzman\",\"Luke Zettlemoyer\"],\"description\":\"QLoRA combined quantization with LoRA to enable fine-tuning of extremely large models on consumer hardware. It quantized the base model to 4-bit precision while using LoRA adapters in higher precision, maintaining full fine-tuning performance. QLoRA made it possible to fine-tune a 65B parameter model on a single GPU with 48GB memory, dramatically democratizing access to fine-tuning large language models and enabling researchers with limited resources to customize state-of-the-art models.\",\"icon\":\"ml/washington.png\",\"details\":\"Implement QLoRA by loading the base model in 4-bit NF4 or FP4 quantization (e.g., bitsandbytes) to save memory, while inserting LoRA adapters (rank 8–64) on key/value and feedforward projections. During fine-tuning, only the LoRA parameters (and optionally LayerNorms/biases) are updated; quantized weights remain frozen, so gradients skip them. Use double quantization to compress quantization constants, and apply paged optimizers to handle long sequences. After training, merge LoRA adapters into the quantized model or keep them separate for modular deployment.\",\"repo\":\"https://github.com/artidoro/qlora\"},{\"id\":\"MoE_Test_Time\",\"period\":\"2024\",\"title\":\"Mixture-of-Experts (MoE) and Test-Time Compute Scaling\",\"org\":\"Google, xAI, DeepSeek\",\"location\":\"https://arxiv.org/pdf/2401.04088.pdf\",\"paperTitle\":\"Mixtral of Experts\",\"authors\":[\"Albert Q. Jiang\",\"Alexandre Sablayrolles\",\"Antoine Roux\",\"Arthur Mensch\",\"Blanche Savary\",\"Chris Bamford\",\"Devendra Singh Chaplot\",\"Diego de las Casas\",\"Emma Bou Hanna\",\"Florian Bressand\",\"Gianna Lengyel\",\"Guillaume Bour\",\"Guillaume Lample\",\"Lélio Renard Lavaud\",\"Lucile Saulnier\",\"Marie-Anne Lachaux\",\"Pierre Stock\",\"Sandeep Subramanian\",\"Sophia Yang\",\"Szymon Antoniak\",\"Teven Le Scao\",\"Théophile Gervet\",\"Thibaut Lavril\",\"Thomas Wang\",\"Timothée Lacroix\",\"William El Sayed\"],\"description\":\"Modern Mixture-of-Experts architectures like Mixtral, Grok, and DeepSeek-V2 combined sparse routing with test-time compute scaling, allowing models to dynamically allocate computation based on task difficulty. These architectures activated only a subset of parameters per token while maintaining large total capacity, achieving better performance-per-compute ratios. The combination with test-time scaling, where models use more computation for harder problems, represented a shift toward more efficient and adaptive AI systems.\",\"icon\":\"ml/google.png\",\"details\":\"To build Mixtral-style MoE with test-time scaling, train a sparse MoE Transformer (top-2 routing) where each token consults two experts. At inference, expose a compute knob: for easy queries evaluate with k=2 experts, for harder questions increase k or recursively reroute through additional experts. Implement routing confidence via gate entropy or response uncertainty, and schedule extra passes only when needed. Combine with key-value cache sharing so expanded compute only touches selected layers. Monitor latency vs. accuracy curves to tune the compute-scaling policy.\"},{\"id\":\"Layer_Dropping\",\"period\":\"2024\",\"title\":\"Layer Dropping and Progressive Pruning (TrimLLM)\",\"org\":\"Northeastern University, Indiana University Bloomington, University of Connecticut, University of Massachusetts Dartmouth, North Carolina State University\",\"location\":\"https://arxiv.org/pdf/2406.02629.pdf\",\"paperTitle\":\"TrimLLM: Progressive Layer Dropping for Efficient LLM Inference\",\"authors\":[\"Lei Lu\",\"Zhepeng Wang\",\"Runyu Peng\",\"Mengbing Wang\",\"Fangyi Zhu\",\"Zilong Wang\",\"Hong Xu\",\"Shangguang Wang\"],\"description\":\"Layer dropping and progressive pruning techniques enabled efficient inference by selectively skipping or removing transformer layers based on input characteristics or layer importance. Research showed that many layers in large language models are redundant for certain tasks, and adaptive layer selection could maintain performance while reducing computation. These techniques became important for deploying large models in resource-constrained environments and improving inference efficiency.\",\"icon\":\"ml/northeastern.png\",\"details\":\"Implement TrimLLM by ranking transformer layers via sensitivity metrics (layer-wise gradients or Fisher scores), then progressively pruning lowest-importance layers while fine-tuning on task data. During inference, use gating functions that inspect input difficulty (e.g., entropy of intermediate activations) to decide how many upper layers to execute. Maintain residual adapters so pruned layers can be skipped without shape mismatches. Evaluate by measuring latency vs. accuracy trade-offs, and deploy policies that drop more layers for easy inputs while keeping full depth for hard cases.\"},{\"id\":\"Multimodal_Secure\",\"period\":\"2024\",\"title\":\"Multimodal Secure Alignment\",\"org\":\"Carnegie Mellon University, University of Washington\",\"location\":\"https://arxiv.org/pdf/2404.12464.pdf\",\"paperTitle\":\"Defending Against Jailbreak Attacks in Multimodal Language Models\",\"authors\":[\"Xuguang Wang\",\"Xin Eric Wang\"],\"description\":\"Multimodal secure alignment addresses unique safety challenges when language models process multiple modalities (text, images, audio). Research revealed that multimodal models could be more vulnerable to jailbreaks through adversarial images or cross-modal attacks. New alignment techniques were developed to ensure consistent safety behavior across modalities, including modality-specific safety layers and cross-modal consistency checking. This work became critical as vision-language models like GPT-4V and Gemini became widely deployed.\",\"icon\":\"ml/cmu.png\",\"details\":\"To harden multimodal LLMs, add modality-specific safety filters (e.g., CLIP-based image classifiers for unsafe content) before feeding inputs to the main model, and enforce cross-modal consistency by verifying that textual responses align with visual content. Train with adversarial data: generate jailbreak images/prompts and fine-tune the model (or a guard model) to reject them. Implement cascading defenses: preprocess images, run policy models that check textual outputs, and add refusal templates. Evaluate via red-teaming on mixed-modal attacks and track false positives vs. jailbreak success rates.\"},{\"id\":\"chain_of_thought_monitorability\",\"period\":\"2025\",\"title\":\"Chain-of-Thought Monitorability\",\"org\":\"Google DeepMind, Anthropic\",\"location\":\"https://doi.org/10.48550/arXiv.2507.05246\",\"paperTitle\":\"When Chain of Thought is Necessary, Language Models Struggle to Evade Monitors\",\"authors\":[\"Scott Emmons\",\"Erik Jenner\",\"David K. Elson\",\"Rif A. Saurous\",\"Senthooran Rajamanoharan\",\"Heng Chen\",\"Irhum Shafkat\",\"Rohin Shah\"],\"description\":\"This work reframed chain-of-thought (CoT) safety monitoring around monitorability rather than faithfulness, distinguishing CoT-as-rationalization from CoT-as-computation. By making harmful behaviors require multi-step reasoning, the authors forced models to expose their plans and showed that CoT monitoring can detect severe risks unless attackers receive substantial assistance. The paper also offered stress-testing guidelines, concluding that CoT monitoring remains a valuable, if imperfect, layer of defense that warrants active protection and continual evaluation.\",\"icon\":\"ml/deepmind.svg\",\"details\":\"To replicate CoT monitorability experiments, construct tasks where harmful actions require multi-step reasoning (e.g., multi-hop jailbreak prompts). Force the model to produce reasoning logs (scratchpads), then train a separate monitor model to classify whether a reasoning chain leads toward disallowed goals. Stress-test by training an adversary model to obscure intent and measure how much assistance it needs to evade detection. Deploy by running the monitor in parallel with the assistant: if the monitor flags risky intent, block or request human review.\"},{\"id\":\"CRFT\",\"period\":\"2025\",\"title\":\"Critical Representation Fine-Tuning (CRFT)\",\"org\":\"Zhejiang University, Alibaba Cloud Computing\",\"location\":\"https://doi.org/10.48550/arXiv.2507.10085\",\"paperTitle\":\"Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning\",\"authors\":[\"Chenxi Huang\",\"Shaotian Yan\",\"Liang Xie\",\"Binbin Lin\",\"Sinan Fan\",\"Yue Xin\",\"Deng Cai\",\"Chen Shen\",\"Jieping Ye\"],\"description\":\"CRFT extends Representation Fine-Tuning by identifying \\\"critical\\\" hidden representations that aggregate or gate reasoning signals, then editing them in a low-rank subspace while freezing the base LLaMA or Mistral weights. Information-flow analysis selects these high-leverage states, enabling large CoT accuracy gains across eight arithmetic and commonsense benchmarks as well as sizeable one-shot improvements. The work highlights that representation-level PEFT can unlock better reasoning without touching most model parameters.\",\"icon\":\"ml/zhejiang_university.svg\",\"details\":\"Implement CRFT by first tracing information flow through each transformer layer using techniques like integrated gradients or attention rollout to identify tokens/neuron activations most correlated with reasoning success. For selected “critical representations,” insert low-rank adapters (similar to LoRA) that are optimized while keeping base weights frozen. Train adapters on reasoning datasets with chain-of-thought supervision, focusing updates on critical subspaces. Evaluate by comparing reasoning accuracy and one-shot improvements relative to LoRA/IA^3 baselines.\"},{\"id\":\"OOCR_Steering_Vectors\",\"period\":\"2025\",\"title\":\"Mechanistic OOCR Steering Vectors\",\"org\":\"Massachusetts Institute of Technology, Independent Researchers\",\"location\":\"https://doi.org/10.48550/arXiv.2507.08218\",\"paperTitle\":\"Simple Mechanistic Explanations for Out-Of-Context Reasoning\",\"authors\":[\"Atticus Wang\",\"Joshua Engels\",\"Oliver Clive-Griffin\",\"Senthooran Rajamanoharan\",\"Neel Nanda\"],\"description\":\"This study dissects out-of-context reasoning (OOCR) and finds that many reported cases arise because LoRA fine-tuning effectively adds a constant steering vector that pushes models toward latent concepts. By extracting or directly training such steering vectors, the authors reproduce OOCR across risky/safe decision, function, location, and backdoor benchmarks, showing that unconditional steering can even implement conditional behaviors. The results provide a simple mechanistic account of why fine-tuned LLMs can generalize far beyond their training distribution and highlight the alignment implications of steering-vector interventions.\",\"icon\":\"ml/mit.png\",\"details\":\"To experiment with OOCR steering vectors, compute the mean delta between a LoRA-fine-tuned model’s activations and the base model at a chosen layer, averaged over training prompts. Treat this delta as a steering vector v. During inference with the base model, modify activations h by h′ = h + α·v (or subtract to disable behavior). Sweep α to control strength and observe out-of-context behaviors on evaluation suites (risky/safe, function, location tasks). Alternatively, directly optimize v by gradient descent to maximize a target objective while keeping base weights frozen. Monitor side effects by checking alignment metrics and add gating so steering only activates for specific prompts.\"}]}]]}],[\"$L8\",\"$L9\"],\"$La\"]}],{},null,false,false]},null,false,false]},null,false,false]},null,false,false],\"$Lb\",false]],\"m\":\"$undefined\",\"G\":[\"$c\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"d:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"OutletBoundary\"]\ne:\"$Sreact.suspense\"\n10:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"ViewportBoundary\"]\n12:I[97367,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"MetadataBoundary\"]\n8:[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/0c61c8691d9d95a7.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]\n9:[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/35d043138a0d6b40.js\",\"async\":true,\"nonce\":\"$undefined\"}]\na:[\"$\",\"$Ld\",null,{\"children\":[\"$\",\"$e\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@f\"}]}]\nb:[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L10\",null,{\"children\":\"$@11\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$L12\",null,{\"children\":[\"$\",\"$e\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@13\"}]}]}],null]}]\n"])</script><script>self.__next_f.push([1,"11:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"14:I[27201,[\"/_next/static/chunks/ff1a16fafef87110.js\",\"/_next/static/chunks/247eb132b7f7b574.js\"],\"IconMark\"]\n13:[[\"$\",\"title\",\"0\",{\"children\":\"Henrik Nordberg, Principal Engineer\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Henrik Nordberg's project showcase\"}],[\"$\",\"link\",\"2\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"link\",\"4\",{\"rel\":\"apple-touch-icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"$L14\",\"5\",{}]]\nf:null\n"])</script></body></html>